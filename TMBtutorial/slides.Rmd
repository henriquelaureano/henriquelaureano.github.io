---
title: "Implementando modelos estatísticos\\newline
        de maneira eficiente com o TMB"
subtitle: Um tutorial
author: Henrique Laureano, Ricardo Petterle & Wagner Bonat
date: 9 de setembro, 2021
institute: LEG @ UFPR
classoption: [aspectratio=169]
bibliography: references.bib
link-citations: yes
output:
  beamer_presentation:
    includes:
      in_header: beamerheader.txt
---

### TMB: Template Model Builder

\bigskip
\begin{columns}
 \column{\linewidth/3}
  \centering
   \includegraphics[height=3.6cm]{logo/what.png}\\
   \bigskip
   \textcolor{UniBlue}{\textbf{O quê?}}
 \column{\linewidth/3}
  \centering
   \includegraphics[height=3.6cm]{logo/why.jpg}\\
   \bigskip
   \textcolor{UniBlue}{\textbf{Por quê?}}
 \column{\linewidth/3}
  \centering
   \includegraphics[height=3.6cm]{logo/roll_safe.png}\\
   \bigskip
   \textcolor{UniBlue}{\textbf{Como?}}
\end{columns}

### O que é o Template Model Builder?

Pelas palavras dos autores:

\includegraphics[height=0.5cm]{logo/book.png}
@TMB.

\bigskip
> Um pacote R [@R21] para a rápida implementação de complexos modelos de
> efeitos aleatórios através de simples *templates* C++.

\textcolor{UniBlue}{\textbf{Complexos modelos de efeitos aleatórios?}}
Do simples ao complicado.

\vspace{-0.2cm}
\begin{minipage}{9.5cm}
 \begin{block}{}
  \vspace{0.1cm}
  De modelos simples como um
  \vspace{0.1cm}
  \begin{itemize}
   \item um modelo linear (\textbf{LM}) ou
   \item um modelo linear generalizado (\textbf{GLM}),
  \end{itemize}
  \vspace{0.1cm}
  até
  \vspace{0.1cm}
  \begin{itemize}
   \item \textbf{modelos não-lineares com efeitos aleatórios} e
   \item complexos \textbf{modelos espaço-temporais}.
  \end{itemize}
  \vspace{0.1cm}
 \end{block}
\end{minipage}

### Inúmeras possibilidades...

1. Estudar o efeito de características numa certa variável?
   **Modelos lineares** (LM);

2. A resposta é não-Normal/Gaussiana?
   **Modelos lineares generalizados** (GLM);

3. Função não-linear nos parâmetros? **Modelos não-lineares**;

4. Múltiplas respostas/variáveis? **Modelos multivariados**;

5. Presença de dependência não-observada/latente?\
   **Modelos de efeito aleatório/latente/misto**.

   1. Modelos para **dados longitudinais**
      (medidas repetidas, séries temporais);
      
   2. Modelos para **dados espaciais** e **espaço-temporais**;

6. ...

\bigskip
\textcolor{UniBlue}{\textbf{O TMB possibilita o ajuste de todos esses
                            modelos}}.

### TMB: Automatic Differentiation and Laplace Approximation

Características-chave:
\begin{multicols}{2}
 \begin{enumerate}
  \item Diferenciação automática;\newline
        \textit{o estado-da-arte na computação de derivadas}
  \item Aproximação de Laplace.\newline
        \textit{Uma maneira eficiente de aproximar as integrais do
                efeito aleatório}
 \end{enumerate}
\end{multicols}

\vspace{-0.2cm}
\begin{block}{Um pouco de matemática para justificar as coisas...}
 Considere que \(f(u, \theta)\) seja o
 \vspace{-0.15cm}
 \[
  \text{negativo da sua função de log-verossililhança
        \textbf{\textcolor{AlertOrange}{conjunta} nll})},
 \]
 \vspace{-0.6cm}
 
 em que \(u \in \mathbb{R}^{n}\) são os
 \textbf{efeitos aleatórios desconhecidos}
 e \(\theta \in \mathbb{R}^{m}\) são os \textbf{parâmetros}. 
\end{block}

\begin{description}
 \item[\textcolor{AlertOrange}{Conjunta?}]
  Num modelo estatístico especificamos uma distribuição de
  probabilidade para o que observamos (\textbf{dados}) e
  outra para o que não observamos (\textbf{efeito aleatório}).
  \textcolor{UniBlue}{\textbf{E é aí que mora o problema}}!
\end{description}

### Por que usar o TMB?

\begin{description}
 \item[Paradigmas:] Verossimilhancista e Bayesiano.
  \begin{description}
   \item[Bayesiano:] Atribuição de distribuições ã \textit{priori} para
                     os parâmetros, que passam a serem vistos como
                     variáveis. Não mais estimamos os "parâmetros", e
                     sim amostramos de sua distribuição a
                     \textit{posteriori}. Funciona, mas é
                     \textbf{computacionalmente intensivo}.
   \item[Verossimilhancista:] Temos um problema, já que o efeito
                              aleatório é \textbf{não observável}.
                              Contudo, da estatística básica: se temos
                              uma
                              \textcolor{AlertOrange}{\textbf{conjunta}},
                              basta \textbf{integrarmos} na variável que
                              não queremos mais. Resultando numa
  \end{description}
\end{description}

\begin{block}{}
 \vspace{-0.2cm}
 \[
  \text{Função de verossimilhança
        \textcolor{AlertOrange}{\textbf{marginal}}}:\qquad
  L(\theta) = \int_{\mathbb{R}^{n}} \text{exp}(-f(u, \theta))~\text{d}u.
 \]
\end{block}

Bem, essa é a ideia básica. Na prática não é bem assim...

### Na prática

Quando a distribuição que especificamos pro **dado** não é Gaussiana,\
não conseguimos resolver aquela integral analíticamente.

\begin{block}{}
 \vspace{-0.35cm}
 \[
  \def\hat{\mathaccent "705E\relax}
  \text{Aí que entra a
        \textcolor{UniBlue}{\textbf{aproximação de Laplace}}}:\quad
  L^{\star}(\theta) = \sqrt{2\pi}^{n}
                      \text{det}(H(\theta))^{-1/2}
                      \text{exp}(-f(\hat{u}, \theta)),
  \vspace{-0.2cm}
 \]
 com
 \vspace{0.15cm}
 \begin{itemize}
  \item \(\def\hat{\mathaccent "705E\relax}
          H(\theta) = f_{uu}^{''}(\hat{u}(\theta), \theta)\) sendo o
        Hessiano de \(f(u, \theta)\) w.r.t. \(u\) e avaliado em
        \(\def\hat{\mathaccent "705E\relax} \hat{u}(\theta)\);
  \vspace{0.15cm}
  \item \(\def\hat{\mathaccent "705E\relax}
          \hat{u}(\theta) =
          \text{arg}~\underset{u}{\text{min}}~f(u, \theta)\) sendo o
        minimizador de \(f(u, \theta)\) w.r.t. \(u\).
 \end{itemize}
 \vspace{0.15cm}
 \textbf{Finalmente},\newline
 a função objetivo final a ser minimizada em termos de
 \(\theta\) é
 \vspace{-0.1cm}
 \[
  \def\hat{\mathaccent "705E\relax}
  \color{AlertOrange}{-\log L^{\star}(\theta) =
  -n\log \sqrt{2\pi} +
  \frac{1}{2}\log \text{det}(H(\theta)) +
  f(\hat{u}, \theta)},
  \vspace{-0.1cm}
 \]
 i.e., o
 \textcolor{UniBlue}{\textbf{log negativo da aproximação de Laplace}}.
 \vspace{0.1cm}
\end{block}

### Automatic Differentiation (AD)

\vspace{-0.2cm}
\begin{minipage}{11.75cm}
 \begin{block}{Uncertainty quantification: Método-\(\bm{\delta}\)}
  \[
   \def\hat{\mathaccent "705E\relax}
   \text{VAR}(\phi(\hat{\theta}) =
   -\phi_{\theta}^{'}(\hat{\theta}))
   (\bigtriangledown^{2}\log L^{\star}(\hat{\theta}))^{-1}
   \phi_{\theta}^{'}(\hat{\theta})^{\top},
   \vspace{-0.15cm}
  \]
  ou seja,\newline
  conseguimos quantificar a incerteza da estimativa
  \(\def\hat{\mathaccent "705E\relax} \hat{\theta}\), e de qualquer
  função diferenciável da estimativa
  \(\def\hat{\mathaccent "705E\relax} \phi(\hat{\theta})\).
  \vspace{0.1cm}
 \end{block}
\end{minipage}

\vspace{0.1cm}
Em todas as etapas

- Aproximação de Laplace (*otimização interna*);

- Log negativo da aproximação de Laplace (*otimização externa*);

- Quantificação da incerteza,

o cálculo de derivadas (1a e 2a ordem) é essencial.\
**Portanto**, sermos capazes de usar a
\textcolor{UniBlue}{\textbf{maneira mais eficiente existente}}\
*hoje* pra calcular essas derivadas, é uma tremenda
\textcolor{UniBlue}{\textbf{qualidade}}.

### Diferenciação automática (AD) em um exemplo

Considere a função (\includegraphics[height=0.5cm]{logo/book.png}
exemplo tirade de @peyre[, página 33])
\begin{block}{}
 \vspace{-0.15cm}
 \[
  f(x, y) = y\log(x) + \sqrt{y\log(x)}
 \]
\end{block}

O que a \textcolor{UniBlue}{\textbf{AD}} internamente faz é decompor a
função em *nodos*, construir um ***grafo***

\begin{center}
 \includegraphics[height=2.25cm]{ex-computational_graph.png}
\end{center}

e trabalhar em cima do mesmo.

Existem dois **modos** de avaliar a função via
\textcolor{UniBlue}{\textbf{AD}}. O modo **forward** e o modo
**reverse**.\
O que o \textcolor{UniBlue}{\textbf{TMB}} faz é o **reverse**,
\textcolor{AlertOrange}{\textbf{computationalmente mais eficiente}}.

### AD: modo reverso

\begin{columns}
 \column{5.5cm}
  Função:
  \vspace{-0.2cm}
  \begin{block}{}
   \vspace{-0.5cm}
   \[
    f(x, y) = y\log(x) + \sqrt{y\log(x)}
   \]
  \end{block}
 \column{9.5cm}
   \includegraphics[height=1.75cm]{ex-computational_graph.png}
\end{columns}

\vspace{-0.35cm}
\begin{align*}
 \frac{\partial f}{\partial f} &= 1\\
 \frac{\partial f}{\partial c} &=
 \frac{\partial f}{\partial f} \frac{\partial f}{\partial c} =
 \frac{\partial f}{\partial f} 1\qquad &\{c \mapsto f = b + c\}\\
 \frac{\partial f}{\partial b} &=
 \frac{\partial f}{\partial c} \frac{\partial c}{\partial b} +
 \frac{\partial f}{\partial f} \frac{\partial f}{\partial b} =
 \frac{\partial f}{\partial c} \frac{1}{2\sqrt{b}} +
 \frac{\partial f}{\partial f} 1\qquad
 &\{b \mapsto c = \sqrt{b},~b \mapsto f = b + c\}\\
 \frac{\partial f}{\partial a} &=
 \frac{\partial f}{\partial b} \frac{\partial b}{\partial a} =
 \frac{\partial f}{\partial b} y\qquad &\{a \mapsto b = ya\}\\
 \frac{\partial f}{\partial y} &=
 \frac{\partial f}{\partial b} \frac{\partial b}{\partial y} =
 \frac{\partial f}{\partial b} a \qquad &\{y \mapsto b = ya\}\\
 \frac{\partial f}{\partial x} &=
 \frac{\partial f}{\partial a} \frac{\partial a}{\partial x} =
 \frac{\partial f}{\partial a} \frac{1}{x} \hspace{6.5cm}
 &\{x \mapsto a = \log(x)\}
\end{align*}

### TMB: Template Model Builder

\large
\textcolor{UniBlue}{\textbf{Como usar?}}

\vspace{0.15cm}
\normalsize
\begin{block}{Workflow}
 \vspace{0.15cm}
 \begin{enumerate}
  \item Escreva sua função objetivo em um \texttt{.cpp} com
        \texttt{\#include <TMB.hpp>};

  \vspace{0.15cm}
  \item Compile e carregue seu arquivo \texttt{.cpp} em R via
        \texttt{TMB::compile()} e
        \texttt{base::dyn.load(TMB::dynlib())};

  \vspace{0.15cm}
  \item Compute as derivadas da sua função objetivo com
        \texttt{obj <- TMB::MakeADFun()};

  \vspace{0.15cm}
  \item Faça o ajuste do modelo,
        \texttt{opt <- base::nlminb(obj\$par, obj\$fn, obj\$gr)};

  \vspace{0.15cm}
  \item Quantifique a incerteza dos parâmetros,
        \texttt{TMB::sdreport(obj)}.
 \end{enumerate}
 \vspace{0.15cm}
\end{block}

\large
\textcolor{UniBlue}{\textbf{(Extra) Funcionalidades}}

\normalsize

### TMB

Key features:
\begin{multicols}{2}
 \begin{enumerate}
  \item Automatic differentiation;\newline
        \textit{The state-of-art in derivatives computation}
  \item Laplace approximation.\newline
        \textit{An efficient fashion to approximate the latent effect
                integrals}
 \end{enumerate}
\end{multicols}

\includegraphics[height=0.5cm]{logo/book.png}
For details about TMB, AD, and Laplace approximation: @laurence.

### Ideia de estrutura (slide 1 de 2)

\begin{minipage}{11.5cm}
 \begin{block}{}
  Quatro pontos principais:\newline
  \textbf{o que é}, \textbf{por quê usar},
  \textbf{estrutura e características}, e \textbf{exemplos}.
 \end{block}
\end{minipage}

\bigskip

1. Explicar em um slide **o que é** o TMB;

2. Tá, mas **por que usar** o TMB?

   1. **Motivação**: modelos mistos;
  
   2. **Exemplos**: dados longitudinais, modelos multivariados,\
      espaciais
      (espaço-temporal, talvez pra mostrar quão longe podemos ir);
      
   3. Não dá pra falar bem dessas coisas sem explicar o que é\
      e qual a estrutura de um **GLM** e de um **GLMM**;
      
   4. Consequentemente, falar do *calcanhar de Aquiles* dum GLMM:\
      como fazer a **marginalização** de maneira eficiente ->
      aproximação de Laplace;

### Ideia de estrutura (slide 2 de 2)

3. **Estrutura e características** do TMB:

   1. C++;

   2. Bibliotecas eficientes (listar elas) e paralelismo;

   3. **Diferenciação automática**\
      (um exemplo, talvez o da minha dissertação);

### Referências
