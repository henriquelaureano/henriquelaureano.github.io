\documentclass[12pt, oldfontcommands]{article}
\usepackage[english]{babel}
%\usepackage[brazilian, brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[top = 2cm, left = 2cm, right = 2cm, bottom = 2cm]{geometry}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{multicol}
\usepackage{vwcol}
\usepackage[normalem]{ulem}
\usepackage{breqn}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{threeparttable}
\setlength\parindent{0pt}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

\title{
 \normalfont \normalsize 
 \textsc{STAT 260 - Nonparametric Statistics} \\
 Ying Sun \\
 Statistics (STAT) Program \\
 Computer, Electrical and Mathematical Sciences \& Engineering (CEMSE) Division \\
 King Abdullah University of Science and Technology (KAUST) \\[25pt]
 \horrule{.5pt} \\[.4cm]
 \LARGE HOMEWORK \\
  IV
 \horrule{2pt} \\[.5cm]}
 
\author{Henrique Aparecido Laureano}
\date{\normalsize Spring Semester 2018}

\begin{document}

\maketitle

% \newpage

\vspace{\fill}

\tableofcontents

\horrule{1pt} \\

\newpage

<<setup, include=FALSE>>=
# <r code> ===================================================================== #
library(knitr)

tema <- knit_theme$get("acid")

knit_theme$set(tema)

opts_chunk$set(size='small'
               , cache=TRUE
               , cache.path='cache/'
               , comment=NA
               , warning=FALSE
               , message=FALSE
               , fig.align='center'
               , dpi=100
               , fig.path='iBagens/'
               , fig.pos='H'
               , background='#ffffff'
               , results='hold'
               , fig.show='hold')
# </r code> ==================================================================== #
@

\section*{Problem 1} \addcontentsline{toc}{section}{Problem 1}

\horrule{1pt}

\begin{description}
 \item
 \textbf{This question is about illustrating the problems with polynomial bases.
         First run} \hfill
<<>>=
# <r code> ===================================================================== #
set.seed(1)                      # setting the "seed" to have always the same data
x <- sort(runif(40)*10)**.5                                         # generating x
y <- sort(runif(40))**.1                                            # generating y
# </r code> ==================================================================== #
@
 \textbf{to simulate some apparently innocuous \(x\), \(y\) data.}
<<fig.width=4.5, fig.height=4, fig.cap="Some apparently innocuous $x$, $y$ data.">>=
# <r code> ===================================================================== #
par(mar = c(4, 4, 2, 2) + .1) ; plot(x, y)                          # plotting ...
# </r code> ==================================================================== #
@
\end{description}

\subsection*{(a)} \addcontentsline{toc}{subsection}{(a)}

\horrule{.5pt} \\

\textbf{Fit 5th and 10th order polynomials to the simulated data using, e.g.,
        \texttt{lm(y \(\sim\) poly(x, 5))}.}

\begin{description}
 \item[Solution:] \hfill
<<>>=
# <r code> ===================================================================== #
poly5 <- lm(y ~ poly(x, 5)) ; poly10 <- lm(y ~ poly(x, 10))
# </r code> ==================================================================== #
@
\end{description}
 
\hfill \(\square\)

\subsection*{(b)} \addcontentsline{toc}{subsection}{(b)}

\horrule{.5pt} \\

\textbf{Plot the \(x\), \(y\) data, and overlay the fitted polynomials. (Use the
        \texttt{predict} function to obtain predictions on a fine grid over the
        range of the \(x\) data: only predicting at the data fails to illustrate
        the polynomial behavior adequately).}

\begin{description}
 \item[Solution:] \hfill
<<fig.width=4.5, fig.height=4, fig.cap="Data with overlay of the fitted polynomials (5th order in red and 10th order in blue).">>=
# <r code> ===================================================================== #
grid <- seq(min(x), max(x), length = 200)     # 5 times more points (40 * 5 = 200)
par(mar = c(4, 4, 2, 2) + .1) ; plot(x, y)  # graphical definition & plotting data
                                      # overlaying the 5th order fitted polynomial
lines(grid, predict(poly5, data.frame(x = grid)), col = 2, lwd = 2)
                                     # overlaying the 10th order fitted polynomial
lines(grid, predict(poly10, data.frame(x = grid)), col = "#0080ff", lwd = 2)
# </r code> ==================================================================== #
@
We see how the 10th order fitted polynomial chase the data and how he lost
himself between the initial points of \(x\) because we don't have data in that
interval.
\end{description}

\hfill \(\square\)

\subsection*{(c)} \addcontentsline{toc}{subsection}{(c)}

\horrule{.5pt} \\

\textbf{One particularly simple basis for a cubic regression spline is
        \(b_{2}(x) = x\) and \(b_{j + 2}(x) = \mid x - x_{j}^{\ast} \mid^{3}\) for
        \(j = 1, \dots, q - 2\), where \(q\) is the basis dimension, and the
        \(x_{j}^{\ast}\) are knot locations. Use this basis to fit a rank 11 cubic
        regression spline to the \(x\), \(y\) data (using \texttt{lm} and evenly
        spaced knots).}

\begin{description}
 \item[Solution:] \hfill
<<>>=
# <r code> ===================================================================== #
rank <- 11                                              # rank of the cubic spline
x_j <- ( ( 1:(rank - 2) / (rank - 1) )*10 )**.5                   # defining x_{j}
basis <- function(x, x_j) abs(x - x_j)**3                  # defining simple basis
           # constructing the formula for the basis of the cubic regression spline
fm <- paste0("basis(x, x_j[", 1:(rank - 2), "])", collapse = "+")
fm <- paste("y ~ x +", fm)
cs <- lm(formula(fm))         # fitting the model, cs: "c"ubic regression "s"pline
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsection*{(d)} \addcontentsline{toc}{subsection}{(d)}

\horrule{.5pt} \\

\textbf{Overlay the predicted curve according to the spline model, onto the
        existing \(x\), \(y\) plot, and consider which basis you would rather
        use.}

\begin{description}
 \item[Solution:] \hfill
<<fig.width=4.5, fig.height=4, fig.cap="Data with overlay of the fitted polynomials (5th order in red and 10th order in blue) and the  predicted cubic regression spline curve, in green.">>=
# <r code> ===================================================================== #
par(mar = c(4, 4, 2, 2) + .1) ; plot(x, y)  # graphical definition & plotting data
                                      # overlaying the 5th order fitted polynomial
lines(grid, predict(poly5, data.frame(x = grid)), col = 2, lwd = 2)
                                     # overlaying the 10th order fitted polynomial
lines(grid, predict(poly10, data.frame(x = grid)), col = "#0080ff", lwd = 2)
                          # overlaying the predicted cubic regression spline curve
lines(grid, predict(cs, data.frame(x = grid)), col = 3, lwd = 2)
# </r code> ==================================================================== #
@
\end{description}

The results with the 5th order polynomial and with the rank 11 cubic spline are
quite similar, but with the cubic spline the fit looks more smooth.

\hfill \(\square\)

\section*{Problem 2} \addcontentsline{toc}{section}{Problem 2}

\horrule{1pt} \\

\textbf{Show that the \(\beta\) minimizing
        \(\parallel \mathbf{y} - \mathbf{X} \bm{\beta} \parallel^{2} +
        \bm{\lambda} \bm{\beta}^{\top} \mathbf{S} \bm{\beta}\)
        is given by
        \(\bm{\hat{\beta}} = (\mathbf{X}^{\top} \mathbf{X} +
          \bm{\lambda} \mathbf{S})^{-1} \mathbf{X}^{\top} \mathbf{y}\).} \\

\underline{Solution:}

\begin{align*}
 \parallel \mathbf{y} - \mathbf{X} \bm{\beta} \parallel^{2} +
 \bm{\lambda} \bm{\beta}^{\top} \mathbf{S} \bm{\beta} \\
 (\mathbf{y} - \mathbf{X} \bm{\beta})^{\top}
 (\mathbf{y} - \mathbf{X} \bm{\beta}) +
 \bm{\lambda} \bm{\beta}^{\top} \mathbf{S} \bm{\beta} \\
 \mathbf{y}^{\top}\mathbf{y} - 2 \bm{\beta}^{\top} \mathbf{X}^{\top} \mathbf{y} +
 \bm{\beta}^{\top} \mathbf{X}^{\top} \mathbf{X} \bm{\beta} +
 \bm{\lambda} \bm{\beta}^{\top} \mathbf{S} \bm{\beta} \\
 \mathbf{y}^{\top}\mathbf{y} - 2 \bm{\beta}^{\top} \mathbf{X}^{\top} \mathbf{y} +
 \bm{\beta}^{\top} (\mathbf{X}^{\top} \mathbf{X} + \bm{\lambda} \mathbf{S})
 \bm{\beta},
\end{align*}

Taking the derivative with respect to \(\bm{\beta}\) and setting to zero:

\begin{align*}
 - 2 \mathbf{X}^{\top} \mathbf{y} +
 2 (\mathbf{X}^{\top} \mathbf{X} + \bm{\lambda} \mathbf{S}) \bm{\hat{\beta}} & =
 \mathbf{0} \\
 (\mathbf{X}^{\top} \mathbf{X} + \bm{\lambda} \mathbf{S}) \bm{\hat{\beta}} & =
 \mathbf{X}^{\top} \mathbf{y} \\
 \bm{\hat{\beta}} & =
 (\mathbf{X}^{\top} \mathbf{X} + \bm{\lambda} \mathbf{S})^{-1}
 \mathbf{X}^{\top} \mathbf{y}.
\end{align*}

\hfill \(\square\)

\section*{Problem 3} \addcontentsline{toc}{section}{Problem 3}

\horrule{1pt} \\

\textbf{Let \(\mathbf{X}\) be an \(n \times p\) model matrix, \(\mathbf{S}\) a
        \(p \times p\) penalty matrix, and \(\mathbf{B}\) any matrix such that
        \(\mathbf{B}^{\top} \mathbf{B} = \mathbf{S}\). If
        \(\tilde{\mathbf{X}} = [\mathbf{X}^{\top}, \mathbf{B}^{\top}]^{\top}\) is
        an augmented model matrix, show that the sum of the first \(n\) elements
        on the leading diagonal of
        \(\tilde{\mathbf{X}}(\tilde{\mathbf{X}}^{\top} \tilde{\mathbf{X}})^{-1}
          \tilde{\mathbf{X}}^{\top}\) is
        \({\rm tr}\{\mathbf{X}(\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
                    \mathbf{X}^{\top}\}\).} \\

\underline{Solution:}

\[
 \tilde{\mathbf{X}}^{\top} \tilde{\mathbf{X}} =
 [\mathbf{X}^{\top} \mathbf{B}^{\top}] \begin{bmatrix} \mathbf{X} \\ 
                                                        \mathbf{B}
                                       \end{bmatrix} =
                                       \mathbf{X}^{\top} \mathbf{X} +
                                       \mathbf{B}^{\top} \mathbf{B} =
                                       \mathbf{X}^{\top} \mathbf{X} + \mathbf{S}
\]

\begin{align*}
 \tilde{\mathbf{X}}(\tilde{\mathbf{X}}^{\top} \tilde{\mathbf{X}})^{-1}
 \tilde{\mathbf{X}}^{\top} & =
 \begin{bmatrix} \mathbf{X} \\ 
                 \mathbf{B}
 \end{bmatrix} (\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
 [\mathbf{X}^{\top} \mathbf{B}^{\top}] \\
 & = \begin{bmatrix}
      \mathbf{X} (\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
      \mathbf{X}^{\top} &
      \mathbf{X} (\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
      \mathbf{B}^{\top} \\
      \mathbf{B} (\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
      \mathbf{X}^{\top} &
      \mathbf{B} (\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
      \mathbf{B}^{\top}
     \end{bmatrix}.
\end{align*}

The upper left \(n \times n\) submatrix of
\(\tilde{\mathbf{X}}(\tilde{\mathbf{X}}^{\top} \tilde{\mathbf{X}})^{-1}
  \tilde{\mathbf{X}}^{\top}\) is
\(\mathbf{X}(\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1} \mathbf{X}^{\top}\).
Therefore, the sum of the first \(n\) elements on the leading diagonal is the
\({\rm tr}\{\mathbf{X}(\mathbf{X}^{\top} \mathbf{X} + \mathbf{S})^{-1}
            \mathbf{X}^{\top}\}\).


\hfill \(\square\)

\section*{Problem 4} \addcontentsline{toc}{section}{Problem 4}

\horrule{1pt} \\

\textbf{Read Section 4.2.4 and Section 4.3 of the textbook. The additive model of
        section 4.3 can equally well be estimated as a mixed model.}

\subsection*{(a)} \addcontentsline{toc}{subsection}{(a)}

\horrule{.5pt} \\

\textbf{Write a function which converts the model matrix and penalty returned by
        \texttt{tf.XD} into mixed model form. Hint: because of the constraints the
        penalty null space is of dimension \(1\) now, leading to a slight
        modification of \(D_{+}\).}

\begin{description}
 \item[Solution:] \hfill \\

  First taking the function \texttt{tf.XD} (and dependent functions) from the
  book (sections 4.2.1 and 4.3.1)
<<>>=
# <r code> ===================================================================== #
                               # producing constrained versions of X_{j} and D_{J}
tf.XD <- function(x, xk, cmx = NULL, m = 2) {  # get X and D subject to constraint
  nk = length(xk)                                          # number of knots x_{k}
  X = tf.X(x,xk)[ , -nk]                                    # basis model matrix X
  D = diff(diag(nk), differences = m)[ , -nk]       # square root penalty matrix D
  if (is.null(cmx)) cmx = colMeans(X)   # values to subtract from the columns of X
  X = sweep(X, 2, cmx)                         # subtracting cmx from columns of X
  list(X = X, D = D, cmx = cmx)                                # returning objects
}
   # taking a sequence of knots and an array of x values to produce a model matrix
   #                                               for a piecewise linear function
tf.X <- function(x, xj) {   # tf basis matrix given data x and knot sequence x_{j}
  nk = length(xj) ; n = length(x)                                        # lengths
  X <- matrix(NA, n, nk)                          # creating empthy model matrix X
  for (j in 1:nk) X[ , j] = tf(x, xj, j)                  # filling model matrix X
  X                                                     # returning model matrix X
}
                                           # defining the basis functions b_{j}(x)
tf <- function(x, xj, j) {                                     # tf: tent function
  dj = xj * 0 ; dj[j] = 1#      generating j-th tf from set defined by knots x_{j}
  approx(xj, dj, x)$y                            # performing linear interpolation
}
# </r code> ==================================================================== #
@

Now, writing the function
<<>>=
# <r code> ===================================================================== #
# converting returned constrained model and penalty matrices into mixed model form
mmform <- function(x, xk = NULL, k = 10, sep = TRUE) {
                                           # using default number of knots, k = 10
  if (is.null(xk))                                         #     if x_{k} is null,
    xk = seq(min(x), max(x), length = k)                   # build a grid of knots
  xd = tf.XD(x, xk)            # computing constrained versions of X_{j} and D_{j}
  D = rbind(0, xd$D) ; D[1, 1] = 1                           # doing modifications
  X = t(solve( t(D), t(xd$X) ))                         # computing model matrix X
  if (sep) list(X = X[ , 1, drop = FALSE], Z = X[ , -1], xk = xk)
  else list(X = X, xk = xk) 
}
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsection*{(b)} \addcontentsline{toc}{subsection}{(b)}

\horrule{.5pt} \\

\textbf{Using your function from part (a) obtain the model matrices required to
        fit the two term additive tree model, and estimate it using \texttt{lme}.
        Because there are now two smooths, two \texttt{pdIdent} terms will be
        needed in the \texttt{random} list supplied to \texttt{lme}, which will
        involve two dummy grouping variables (which can just be differently named
        copies of the same variable).}

\begin{description}
 \item[Solution:] \hfill
<<>>=
# <r code> ===================================================================== #
   # generating constrained versions of X_{j} and D_{J} matrices for the variables
x_h <- mmform(trees$Height) ; x_g <- mmform(trees$Girth)

                 # putting together, building model matrix X with intercept column
X <- cbind(1, x_h$X, x_g$X)

Z_h <- x_h$Z ; Z_g <- x_g$Z                # taking square root penalty matrices D

g1 <- g2 <- factor(rep(1, nrow(X)))                  # length of X, number of rows
library(nlme)                                                    # loading library
Y <- trees$Volume                                                # response vector
                                  # fitting the mixed model with positive definite
                                  #            matrices structure of class pdIdent
model <- lme(Y ~ X - 1, random = list(g1 = pdIdent(~ Z_h - 1),
                                      g2 = pdIdent(~ Z_g - 1))
             )
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsection*{(c)} \addcontentsline{toc}{subsection}{(c)}

\horrule{.5pt} \\

\textbf{Produce residual versus fitted volume and raw volume against fitted volume
        plots.}

\begin{description}
 \item[Solution:] \hfill
<<fig.height=4, fig.cap="(a): fitted volume against residues; (b): fitted volume against raw volume.">>=
# <r code> ===================================================================== #
rsd <- Y - fitted(model)                                     # computing residuals
Y_hat <- fitted(model)                                             # fitted values

par(mfrow = c(1, 2))                                       # graphical definitions
                                                                        # plotting
plot(Y_hat, rsd, xlab = "Fitted volume", ylab = "Residues", main = "(a)")
abline(h = 0, lty = 2)                                       # dashed line in zero
plot(Y_hat, Y, xlab = "Fitted volume", ylab = "Raw volume", main = "(b)")
abline(a = 1, b = 1, lty = 2)                                # perfect dashed line
# </r code> ==================================================================== #
@
In (a) we see the values spread between -4 and 4, what is good (but not so good);
and in (b) we see that the values are quite similar, considering the sample size
of 31.
\end{description}

\hfill \(\square\)

\subsection*{(d)} \addcontentsline{toc}{subsection}{(d)}

\horrule{.5pt} \\

\textbf{Produce plots of the two smooth effect estimates with partial residuals.}

\begin{description}
 \item[Solution:] \hfill
<<fig.height=4, fig.cap="(a): height against s(height); (b): girth against s(girth).">>=
# <r code> ===================================================================== #
                                           # getting prediction model matrices X's
X_h <- mmform(trees$Height, xk = x_h$xk, sep = FALSE)$X
X_g <- mmform(trees$Girth, xk = x_g$xk, sep = FALSE)$X

                                        # getting the coefficients for the smooths
coef_h <- as.numeric(coefficients(model)[c(2, 4:11)])                  # s(Height)
coef_g <- as.numeric(coefficients(model)[c(3, 12:19)])                  # s(Girth)

s_h <- X_h %*% coef_h           # doing the computations by the X's model matrices
s_g <- X_g %*% coef_g

par(mfrow = c(1, 2))                                       # graphical definitions
                                                                        # plotting
plot(trees$Height, s_h + rsd, xlab = "Height", ylab = "s(Height)", main = "(a)")
                                                            # addying fitted curve
lines(trees$Height, s_h, col = "#0080ff", lwd = 2)

plot(trees$Girth, s_g + rsd, xlab = "Girth", ylab = "s(Girth)", main = "(b)")
                                                            # addying fitted curve
lines(trees$Girth, s_g, col = "#0080ff", lwd = 2)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\newpage
\section*{Project proposal} \addcontentsline{toc}{section}{Project proposal}

\horrule{1pt} \\

Analyze some datasets using GAMs and GAMMs (when necessary), and with the
bayesian framework. \\

"Which" bayesian framework?

\begin{itemize}
 \item JAGS (\texttt{R} package \texttt{rjags}): Gibbs sampling;
 \item INLA (\texttt{R} package \texttt{INLA}):
       Integrated Nested Laplace Approximation.
\end{itemize}

To compare and to follow a reasoning starting with a more simple model, some
non-bayesian models will be fitted using the \texttt{R} package \texttt{mgcv}. \\

Following the reasoning, some more simple models can also be fitted, as linear
models and mixed linear models. \\

\textbf{Datasets} \\

<<include=FALSE>>=
# <r code> ===================================================================== #
library(SemiPar)
# </r code> ==================================================================== #
@

\textbf{1. Trade union data} \\

Data on 534 U.S. workers with eleven variables (\texttt{SemiPar::trade.union}). \\

\texttt{R summary} output for the dataset:

<<echo=FALSE>>=
# <r code> ===================================================================== #
data(trade.union, package = "SemiPar")

trade.union[ , c(2:3, 5, 8:11)] <- lapply(trade.union[ , c(2:3, 5, 8:11)], factor)

summary(trade.union)
# </r code> ==================================================================== #
@

Colors by \texttt{union.member} status:

<<echo=FALSE, fig.width=6, fig.height=6, fig.cap="Scatter plots and correlations between the numerical variables of the dataset \\texttt{trade.union}.">>=
# <r code> ===================================================================== #
pairs(trade.union[ , c(1, 4, 6:7)]
      , upper.panel = function(x, y, ...) {
        usr <- par("usr") ; on.exit(par(usr)) ; par(usr = c(0, 1, 0, 1))
        r <- abs(cor(x, y))
        txt <- format(c(r, 0.123456789), digits = 2)[1]
        text(.5, .5, txt, cex = 1.25)
      }
      , pch = 16, gap = .25, xaxt = "n", yaxt = "n"
      , col = c("#0080FF", "#F3953E")[unclass(trade.union$union.member)])
# </r code> ==================================================================== #
@

\textbf{2. Sitka spruce data} \\

13 measurements of log-size for 79 Sitka spruce trees grown in normal or
ozone-enriched environments. The first 54 trees have an ozone-enriched atmosphere,
the remaining 25 trees have a normal (control) atmosphere.
(\texttt{SemiPar::sitka}).

\begin{figure}[H]
 \centering
  \includegraphics[width=.4\textwidth]{sitka.jpg}
   \caption{For illustration, Sitka spruce tree.}
\end{figure}

\texttt{R summary} output for the dataset:

<<echo=FALSE>>=
# <r code> ===================================================================== #
data(sitka, package = "SemiPar")

sitka[ , 5] <- as.factor(sitka[ , 5])

summary(sitka)
# </r code> ==================================================================== #
@

In the next par of graphs, each line correspond to a Sikta spruce tree along the
evaluations, in days. \\

More comments are (will be) given in the project proposal presentation.

<<echo=FALSE, fig.height=3.5>>=
# <r code> ===================================================================== #
library(lattice)

print(xyplot(log.size ~ days, subset(sitka, ozone == 0)
             , groups = id.num, type = "l", col = 1
             , xlab = "Days", ylab = "Log-size", main = "Normal atmosphere")
      , position = c(0, 0, .5, 1), more = TRUE)
print(xyplot(log.size ~ days, subset(sitka, ozone == 1)
             , groups = id.num, type = "l", col = 1
             , xlab = "Days", ylab = "Log-size"
             , main = "Ozone-enriched atmosphere")
      , position = c(.5, 0, 1, 1))
# </r code> ==================================================================== #
@

\hfill \(\blacksquare\)

\horrule{.5pt}

\vspace{\fill}

\horrule{1pt} \\

\end{document}