\documentclass[12pt, oldfontcommands]{article}
\usepackage[english]{babel}
%\usepackage[brazilian, brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[top = 2cm, left = 2cm, right = 2cm, bottom = 2cm]{geometry}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{multicol}
\usepackage{vwcol}
\usepackage[normalem]{ulem}
\usepackage{breqn}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{makecell}
\setlength\parindent{0pt}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\newcommand{\Perp}{\perp \! \! \! \perp}
\newcommand{\nPerp}{\cancel{\perp \! \! \! \perp}}

\title{  
 \normalfont \normalsize 
 \textsc{CS 229 - Machine Learning} \\
 Xiangliang Zhang \\
 Computer Science (CS)/Statistics (STAT) Program \\
 Computer, Electrical and Mathematical Sciences \& Engineering (CEMSE) Division \\
 King Abdullah University of Science and Technology (KAUST) \\[25pt]
 \horrule{.5pt} \\ [.4cm]
 \LARGE HOMEWORK \\
  VII
 \horrule{2pt} \\[ .5cm]}
 
\author{Henrique Aparecido Laureano}
\date{\normalsize Spring Semester 2018}

\begin{document}

\maketitle

%\newpage

\vspace{\fill}

\tableofcontents

\horrule{1pt} \\

\newpage

<<setup, include=FALSE>>=
# <r code> ===================================================================== #
library(knitr)

tema <- knit_theme$get("acid")

knit_theme$set(tema)

opts_chunk$set(size='small'
               , cache=TRUE
               , cache.path='cache/'
               , comment=NA
               , warning=FALSE
               , message=FALSE
               , fig.align='center'
               , dpi=100
               , fig.path='iBagens/'
               , fig.pos='H'
               , background='#ffffff'
               , results='hold'
               , fig.show='hold')
# </r code> ==================================================================== #
@

\section*{[30 points] Question 1: \\
                      \textit{Margin} for the maximum-margin hyper-plane \\
          \vspace{0cm} \hfill (Exercise 7.4 of Bishop’s book)}
\addcontentsline{toc}{section}{Question 1:
                               \textit{Margin} for the maximum-margin hyper-plane}

\horrule{1pt}

\begin{figure}[H]
 \centering \includegraphics[width=.4\textwidth]{question1.png}
\end{figure}

\textbf{Show that the value \(\rho\) of the margin for the maximum-margin
        hyperplane is given by}

\[ \frac{1}{\rho^{2}} = \sum_{n = 1}^{N} a_{n} \]

\textbf{where \(\{a_{n}\}\) are given by maximizing}

\[
 \widetilde{L}(\mathbf{a}) = \sum_{n = 1}^{N} a_{n} -
                             \frac{1}{2} \sum_{n = 1}^{N} \sum_{m = 1}^{N}
                             a_{n} a_{m} t_{n} t_{m}
                             k(\mathbf{x}_{n}, \mathbf{x}_{m}) \tag{7.10}
 \label{eq:7.10}
\]

\textbf{subject to the constrains}

\[ a_{n} \geq 0, \quad n = 1, \dots, N, \tag{7.11} \]

\textbf{and}

\[ \sum_{n = 1}^{N} a_{n} t_{n} = 0. \tag{7.12} \]

\underline{Solution}: \\

From the theory of discriminant functions we have that

\[ \rho = \frac{1}{\|\mathbf{w}\|}, \]

with \(\mathbf{w}\) being a weight vector that determines the orientation of the
decision surface. Then we have

\[
 \rho = \frac{1}{\|\mathbf{w}\|} \quad \Rightarrow \quad
 \rho^{2} = \frac{1}{\|\mathbf{w}\|^{2}} \quad \Rightarrow \quad
 \|\mathbf{w}\|^{2} = \frac{1}{\rho^{2}}.
\]

In \eqref{eq:7.10} we have the dual representation of the maximum margin problem,
that is obtained by eliminating \(\mathbf{w}\) and \(b\) from the Lagrangian
function \(L(\mathbf{w}, b, \mathbf{a})\)

\[
 L(\mathbf{w}, b, \mathbf{a}) = \frac{1}{2} \|\mathbf{w}\|^{2} -
                                \sum_{n = 1}^{N} a_{n}
                                \{t_{n} (\mathbf{w}^{\top}
                                         \bm{\phi}(\mathbf{x}_{n}) + b) - 1
                                \}. \tag{7.7}
 \label{eq:7.7}
\]

Setting the derivatives of \(L(\mathbf{w}, b, \mathbf{a})\) w.r.t. \(\mathbf{w}\)
and \(b\) equal to zero, we obtain the following two conditions

\begin{align*}
 \mathbf{w} & = \sum_{n = 1}^{N} a_{n} t_{n} \bm{\phi}(\mathbf{x}_{n}) \tag{7.8}
 \label{eq:7.8} \\
 0 & = \sum_{n = 1}^{N} a_{n} t_{n}. \tag{7.9}
\end{align*}

This constrained optimization problem satisfies (have to satisfie) three KKT
(Karush-Kuhn-Tucker) conditions, that are

\begin{align*}
 a_{n} & \geq 0 \tag{7.14} \\
 t_{n} y(\mathbf{x}_{n})) - 1 & \geq 0 \tag{7.15} \\
 a_{n} \{t_{n} y(\mathbf{x}_{n})) - 1\} & = 0, \tag{7.16} \label{eq:7.16}
\end{align*}

with

\[ y(\mathbf{x}) = \mathbf{w}^{\top} \bm{\phi}(\mathbf{x}) + b. \tag{7.1} \]

And with either \(a_{n} = 0\) or \(t_{n} y(\mathbf{x}_{n})) = 1\). \\

From the condition \eqref{eq:7.16} we see that the summation term disappear in
\eqref{eq:7.7} and then we have

\[ L(\mathbf{w}, b, \mathbf{a}) = \frac{1}{2} \|\mathbf{w}\|^{2}. \]

Combining this with the condition \eqref{eq:7.8}, and remembering that the
kernel function is defined by
\(k(\mathbf{x}_{n}, \mathbf{x}_{m}) = \bm{\phi}(\mathbf{x}_{n}, \mathbf{x}_{m})\),
the dual representation of the maximum margin problem \eqref{eq:7.10} can be
defined as

\[
 \frac{1}{2} \|\mathbf{w}\|^{2} =
 \sum_{n = 1}^{N} a_{n} - \frac{1}{2} \|\mathbf{w}\|^{2} \quad \Rightarrow \quad
 \|\mathbf{w}\|^{2} = \sum_{n = 1}^{N} a_{n}.
\]

Therefore,

\[ \boxed{\frac{1}{\rho^{2}} = \sum_{n = 1}^{N} a_{n}.} \]

\hfill \(\square\)

\section*{[70 points] Question 2: Classification by SVM}
\addcontentsline{toc}{section}{Question 2: Classification by SVM}

\horrule{1pt}

\begin{description}
 \item[Code:]
  \textbf{You could use the
          \href{http://www.csie.ntu.edu.tw/~cjlin/libsvm/}{LIBSVM} Support
          Vector Machine library for the classification; or the built-in Matlab
          SVM functions.} \\

 Here I'm using the \href{https://cran.r-project.org/}{R} language and the package
 \href{https://cran.r-project.org/web/packages/e1071/index.html}{\texttt{e1071}}
 \footnote{\textbf{e1071: Misc Functions of the Department of Statistics,
                   Probability Theory Group (Formerly: E1071), TU Wien}. Functions
           for latent class analysis, short time Fourier transform, fuzzy
           clustering, support vector machines, shortest path computation, bagged
           clustering, naive Bayes classifier, \dots}
<<>>=
# <r code> ===================================================================== #
library(e1071)                                               # loading the library
         # if you don't have the package installed, run: install.packages("e1071")
# </r code> ==================================================================== #
@
 \item[Data:]
  \textbf{You can download the data from
          \url{http://archive.ics.uci.edu/ml/datasets/Wine+Quality}. Take either
          the red-wine or the white-wine data set.} \\
          
  Choosing the red-wine!
<<>>=
# <r code> ===================================================================== #
path <- "~/Dropbox/KAUST/machine_learning/hw7/"                       # files path
                                              # df: dataframe. reading the dataset
df <- read.csv(paste0(path, "winequality-red.csv"), header = TRUE, sep = ";")
# </r code> ==================================================================== #
@
  \textbf{Take “quality” as class label, e.g., 1-5 as \textit{negative}, while
          6-10 as \textit{positive.}}
<<>>=
# <r code> ===================================================================== #
                             # defining class label: 1-5: negative, 6-10: positive
df$quality <- as.factor(ifelse(df$quality <= 5, "negative", "positive"))
table(df$quality)                                                # frequency table
# </r code> ==================================================================== #
@
 \item[Evaluating and Testing:]
  \textbf{Divide the whole data set into training data and testing data, e.g.,
  60\% for training and 40\% for testing. Use 5-fold Cross Validation for setting
  parameters, e.g., C and kernel parameters.}
\end{description}

\textbf{We have 3 different types of models for learning classifiers (SVM with 3
        different types of kernel):}

\begin{itemize}
 \item \textbf{SVM with linear kernel;}
 \item \textbf{SVM with polynomial kernel;}
 \item \textbf{SVM with the radial basis function kernel.}
\end{itemize}

\subsection*{[15 points] (1)} \addcontentsline{toc}{subsection}{(1)}

\horrule{.5pt}

\textbf{For each learning model (each type of kernel), use 60\% of data for
        training SVM model (with the default parameters), and use the remaining
        40\% for testing.}

\begin{description} \item OBS. By default the method \texttt{svm} uses a
                               classification machine algorithm, C-classification,
                               and scale the variables to zero mean and unit
                               variance.
<<>>=
# <r code> ===================================================================== #
          # selecting random row numbers for training data (60% of the whole data)
id <- sample(1:nrow(df), round(nrow(df)*.6, 0))
df.train <- df[id, ]                                    # setting 60% for training
df.test <- df[-id, ]                          # setting the remaining 40% for test
# </r code> ==================================================================== #
@

 \item{Linear kernel:} \(k(x_{i}, x_{j}) = \gamma \|x_{i}, x_{j}\|\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
 # fitting SVM with linear kernel (training data) using all 11 available variables
linear.train <- svm(quality ~ ., df.train, kernel = "linear")
linear.test <- predict(linear.train, df.test[ , -12]) # prediction in testing data
# </r code> ==================================================================== #
@

 \item{Polynomial kernel:}
  \(k(x_{i}, x_{j}) = (c_{0} + \gamma \|x_{i}, x_{j}\|)^{d}\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(c_{0}\)]: default value in \texttt{e1071::svm} is 0;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables);
   \item[\(d\)]: polynominal degree, default value in \texttt{e1071::svm} is 3.
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
   # fitting SVM with poly kernel (training data) using all 11 available variables
poly.train <- svm(quality ~ ., df.train, kernel = "polynomial")
poly.test <- predict(poly.train, df.test[ , -12])     # prediction in testing data
# </r code> ==================================================================== #
@

 \item{Radial kernel:}
  \(k(x_{i}, x_{j}) = \exp(- \gamma \|x_{i}, x_{j}\|)^{2}\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
 # fitting SVM with radial kernel (training data) using all 11 available variables
radial.train <- svm(quality ~ ., df.train, kernel = "radial")
radial.test <- predict(radial.train, df.test[ , -12]) # prediction in testing data
# </r code> ==================================================================== #
@
\end{description}

\subsubsection*{a)} \addcontentsline{toc}{subsubsection}{a)}

\horrule{.25pt}

\textbf{Report the number of support vectors.}

\begin{description}
 \item[Linear kernel]:
  588 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  294 of the class label \textbf{negative} and
  294 of the class label \textbf{positive}.
<<>>=
# <r code> ===================================================================== #
summary(linear.train)
# </r code> ==================================================================== #
@

 \item[Polynomial kernel]:
  659 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  327 of the class label \textbf{negative} and
  332 of the class label \textbf{positive}.
<<>>=
# <r code> ===================================================================== #
summary(poly.train)
# </r code> ==================================================================== #
@

 \item[Radial kernel]:
  605 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  307 of the class label \textbf{negative} and
  298 of the class label \textbf{positive}.
<<>>=
# <r code> ===================================================================== #
summary(radial.train)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsubsection*{b)} \addcontentsline{toc}{subsubsection}{b)}

\horrule{.25pt}

\textbf{Plot the ROC curve of testing results by ranking the decision values
        (3 curves in one figure).}

\begin{description}
 \item \hfill
<<aucs, fig.height=4, fig.width=4, fig.cap="ROC curves of testing results by ranking the decision values.">>=
# <r code> ===================================================================== #
library(pROC)                                                    # loading library
                                   # computing roc curves for the testing datasets
roc.linear <- roc(df.test$quality, as.numeric(linear.test))
roc.poly   <- roc(df.test$quality, as.numeric(poly.test))
roc.radial <- roc(df.test$quality, as.numeric(radial.test))
                                                             # plotting roc curves
plot(roc.linear)
plot(roc.poly, col = "#0080ff", add = TRUE)
plot(roc.radial, col = 2, add = TRUE)
                                                                   # adding legend
legend(x = .55, y = .35, legend = c("Linear", "Polynomial", "Radial")
       , bty = "n", col = c(1, "#0080ff", 2), lwd = 2)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsubsection*{c)} \addcontentsline{toc}{subsubsection}{c)}

\horrule{.25pt}

\textbf{Compute the AUC (Area Under Curve), which kernel is the best?}

\begin{description}
 \item As we can see by the Figure \ref{fig:aucs}, the AUC's (and the ROC curves)
       are very similar. However, by the AUC measure we see that the linear kernel
       is, very slightly, the best (present the bigger, slightly, AUC).
<<>>=
# <r code> ===================================================================== #
auc(roc.linear)
auc(roc.poly)
auc(roc.radial)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsection*{[45 points] (2)} \addcontentsline{toc}{subsection}{(2)}

\horrule{.5pt}

\textbf{For each learning model (each type of kernel), Use 5-fold cross validation
        for setting the parameters of training process. Please note different
        kernels may have different parameters to set. After cross validation,
        choose the best parameter setting, train the model by 60\% of data again
        (the same data used in (1)), test the model by the remaining 40\% of data.
       }
\begin{description}
 \item OBS. By default the method \texttt{svm} uses a classification machine
            algorithm, C-classification, and scale the variables to zero mean and
            unit variance.
  \item{Linear kernel:} \(k(x_{i}, x_{j}) = \gamma \|x_{i}, x_{j}\|\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
   # choosing best cost of constraints violation C by 5-fold Cross Validation (CV)
tune.linear <- tune(svm, quality ~ .        # using all the 11 available variables
                    , data = df.train
                    , kernel = "linear"
                    , tunecontrol = tune.control(cross = 5)            # 5-fold CV
                    , ranges = list(
                         # passing a grid of constraints violation C's, default: 1
                      cost = c(1e-3, 1e-2, .1, .5, 1, 2, 2.5, 3, 5, 7.5, 10),
                               # passing a grid of \gamma's, default: 1/11 = .0909
                      gamma = c(1/1000, 1/100, 1/33, 1/11, 1/3, 1/2, 1)))
tune.linear                                        # best C: .5 and \gamma: 1/1000
# </r code> ==================================================================== #
@
<<>>=
# <r code> ===================================================================== #
                               # fitting SVM with linear kernel (training dataset)
linear_tune.train <- svm(quality ~ ., df.train  # using all 11 available variables
                         , kernel = "linear"
                         , cross = 5                                   # 5-fold CV
                         , cost = .5        # chosen cost of constraints violation
                         , gamma = 1/1000)                         # chosen \gamma
                                                      # prediction in testing data
linear_tune.test <- predict(linear_tune.train, df.test[ , -12])
# </r code> ==================================================================== #
@

 \item{Polynomial kernel:}
  \(k(x_{i}, x_{j}) = (c_{0} + \gamma \|x_{i}, x_{j}\|)^{d}\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(c_{0}\)]: default value in \texttt{e1071::svm} is 0;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables);
   \item[\(d\)]: polynominal degree, default value in \texttt{e1071::svm} is 3.
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
                    # choosing best cost of constraints violation C, c_{0}, \gamma
                    # and kernel polynomial degree by 5-fold Cross Validation (CV)
tune.poly <- tune(svm, quality ~ .          # using all the 11 available variables
                  , data = df.train
                  , kernel = "polynomial"
                  , tunecontrol = tune.control(cross = 5)              # 5-fold CV
                  , ranges = list(
                         # passing a grid of constraints violation C's, default: 1
                    cost = c(1e-3, 1e-2, .1, .5, 1, 2, 2.5, 3, 5),
                                           # passing a grid of c_{0}'s, default: 0
                    coef0 = c(-1, -.5, 0, .5, 1),
                               # passing a grid of \gamma's, default: 1/11 = .0909
                      gamma = c(1/1000, 1/100, 1/33, 1/11, 1/3, 1/2, 1),
                                # passing a grid of polynomial degrees, default: 3
                    degree = c(2, 3, 4, 5)))
tune.poly          # best C: .5; c_{0}: 1; \gamma: 1/11; and kernel poly degree: 3
# </r code> ==================================================================== #
@
<<>>=
# <r code> ===================================================================== #
                           # fitting SVM with polynomial kernel (training dataset)
poly_tune.train <- svm(quality ~ ., df.train    # using all 11 available variables
                       , kernel = "polynomial"
                       , cross = 5                                     # 5-fold CV
                       , cost = .5          # chosen cost of constraints violation
                       , coef0 = 1                                  # chosen c_{0}
                       , gamma = 1/11                              # chosen \gamma
                       , degree = 3)             # chosen kernel polynomial degree
                                                      # prediction in testing data
poly_tune.test <- predict(poly_tune.train, df.test[ , -12])
# </r code> ==================================================================== #
@

 \item{Radial kernel:}
  \(k(x_{i}, x_{j}) = \exp(- \gamma \|x_{i}, x_{j}\|)^{2}\)

  \begin{itemize}
   \item[\(C\)]: default cost of constraints violation in \texttt{e1071::svm} is
                 1;
   \item[\(\gamma\)]: default value in \texttt{e1071::svm} is 1/dataset size
                      (number of variables).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
                        # choosing best cost of constraints violation C and \gamma
                        #                          by 5-fold Cross Validation (CV)
tune.radial <- tune(svm, quality ~ .        # using all the 11 available variables
                    , data = df.train
                    , kernel = "radial"
                    , tunecontrol = tune.control(cross = 5)            # 5-fold CV
                    , ranges = list(
                         # passing a grid of constraints violation C's, default: 1
                      cost = c(1e-3, 1e-2, .1, .5, 1, 2, 2.5, 3, 5, 7.5, 10),
                               # passing a grid of \gamma's, default: 1/11 = .0909
                      gamma = c(1/1000, 1/100, 1/33, 1/11, 1/3, 1/2, 1)))
tune.radial                                           # best C: 5 and \gamma: 1/11
# </r code> ==================================================================== #
@
<<>>=
# <r code> ===================================================================== #
                               # fitting SVM with radial kernel (training dataset)
radial_tune.train <- svm(quality ~ ., df.train  # using all 11 available variables
                  , kernel = "radial"
                  , cross = 5                                          # 5-fold CV
                  , cost = 5                # chosen cost of constraints violation
                  , gamma = 1/11)                                  # chosen \gamma
                                                      # prediction in testing data
radial_tune.test <- predict(radial_tune.train, df.test[ , -12])
# </r code> ==================================================================== #
@
\item OBS. Using 5-fold CV for setting the parameters of training process we saw
           that for each kernel we obtain a different cost of constraints
           violation, \(C\), varying from 0.5 to 5. For the polynomial kernel the
           best polyminal degree wasn't the default, 3, and for this kernel and
           for the radial kernel the best \(\gamma\) was the default value in the
           \texttt{e1071::svm} implementation.
\end{description}

\subsubsection*{a)} \addcontentsline{toc}{subsubsection}{a)}

\horrule{.25pt}

\textbf{Report the setting of parameters.}

\begin{description}
 \item OBS. The step-by-step of the setting of parameters is/was shown above.
<<>>=
# <r code> ===================================================================== #
                            # SVM with linear kernel: reporting setting parameters
linear_tune.train$call
# </r code> ==================================================================== #
@
  \(k(x_{i}, x_{j}) = \gamma \|x_{i}, x_{j}\|\)
  
  \begin{itemize}
   \item[\(C\)]: chosen cost of constraints violation: 0.5.
                 (default vaule in \texttt{e1071::svm}: 1);
   \item[\(\gamma\)]: chosen: 0.001.
                      (default value in \texttt{e1071::svm}:
                       1/number of variables = 0.0909).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
                        # SVM with polynomial kernel: reporting setting parameters
poly_tune.train$call
# </r code> ==================================================================== #
@
  \(k(x_{i}, x_{j}) = (c_{0} + \gamma \|x_{i}, x_{j}\|)^{d}\)
  
  \begin{itemize}
   \item[\(C\)]: chosen cost of constraints violation: 0.5.
                 (default vaule in \texttt{e1071::svm}: 1);
   \item[\(c_{0}\)]: chosen: 1. (default value in \texttt{e1071::svm}: 0);
   \item[\(\gamma\)]: chosen the default value in \texttt{e1071::svm}:
                      1/number of variables = 0.0909;
   \item[\(d\)]: chosen the default polynominal degree in \texttt{e1071::svm}: 3).
  \end{itemize}
<<>>=
# <r code> ===================================================================== #
                            # SVM with radial kernel: reporting setting parameters
radial_tune.train$call
# </r code> ==================================================================== #
@
  \(k(x_{i}, x_{j}) = \exp(- \gamma \|x_{i}, x_{j}\|)^{2}\)
  
  \begin{itemize}
   \item[\(C\)]: chosen cost of constraints violation: 5.
                 (default vaule in \texttt{e1071::svm}: 1);
   \item[\(\gamma\)]: chosen the default value in \texttt{e1071::svm}:
                      1/number of variables = 0.0909.
  \end{itemize}
\end{description}

\hfill \(\square\)

\subsubsection*{b)} \addcontentsline{toc}{subsubsection}{b)}

\horrule{.25pt}

\textbf{Report the number of support vectors.}\begin{description}
 \item[Linear kernel]:
  589 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  295 of the class label \textbf{negative} and
  294 of the class label \textbf{positive}. \\
  (with the default parameters the number of support vectors was 588.)
<<>>=
# <r code> ===================================================================== #
summary(linear_tune.train)
# </r code> ==================================================================== #
@

 \item[Polynomial kernel]:
  558 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  279 of the class label \textbf{negative} and
  279 of the class label \textbf{positive}. \\
  (with the default parameters the number of support vectors was 659.)
<<>>=
# <r code> ===================================================================== #
summary(poly_tune.train)
# </r code> ==================================================================== #
@

 \item[Radial kernel]:
  564 support vectors (the dataset have \Sexpr{nrow(df.train)} samples). \\
  288 of the class label \textbf{negative} and
  276 of the class label \textbf{positive}. \\
  (with the default parameters the number of support vectors was 605.)
<<>>=
# <r code> ===================================================================== #
summary(radial_tune.train)
# </r code> ==================================================================== #
@
\end{description}
\hfill \(\square\)

\subsubsection*{c)} \addcontentsline{toc}{subsubsection}{c)}

\horrule{.25pt}

\textbf{Plot the ROC curve of testing results by ranking the decision values (3
        curves in one figure).}

\begin{description}
 \item \hfill
<<aucs_tune, fig.height=3.9, fig.width=3.9, fig.cap="ROC curves of testing results by ranking the decision values.">>=
# <r code> ===================================================================== #
                                   # computing roc curves for the testing datasets
roc.linear_tune <- roc(df.test$quality, as.numeric(linear_tune.test))
roc.poly_tune   <- roc(df.test$quality, as.numeric(poly_tune.test))
roc.radial_tune <- roc(df.test$quality, as.numeric(radial_tune.test))
                                                             # plotting roc curves
plot(roc.linear_tune)
plot(roc.poly_tune, col = "#0080ff", add = TRUE)
plot(roc.radial_tune, col = 2, add = TRUE)
                                                                   # adding legend
legend(x = .5675, y = .35, legend = c("Linear", "Polynomial", "Radial")
       , bty = "n", col = c(1, "#0080ff", 2), lwd = 2)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsubsection*{d)} \addcontentsline{toc}{subsubsection}{d)}

\horrule{.25pt}

\textbf{Compute the AUC (Area Under Curve), which kernel is the best?}

\begin{description}
 \item As we can see by the Figure \ref{fig:aucs_tune}, the AUC's (and the ROC
       curves) are very similar. However, by the AUC measure we see that the
       linear kernel is, slightly, the best (present the bigger AUC).
<<>>=
# <r code> ===================================================================== #
auc(roc.linear_tune)
auc(roc.poly_tune)
auc(roc.radial_tune)
# </r code> ==================================================================== #
@
\end{description}

\hfill \(\square\)

\subsection*{[10 points] (3)} \addcontentsline{toc}{subsection}{(3)}

\horrule{.5pt}

\textbf{Make a table for comparing the AUC of different kernels with different
        setting of parameters (totally 6 AUC values),  report the 3 best models
        (decided by their AUC values).}

\begin{table}[H]
 \centering
 \caption{AUC's of different kernels with the default and setting parameters.
          In bold is highlighted the best performance for each kernel and
          in red the best of all.}
 \label{tab:aucs}
 \vspace{.25cm}
 \begin{tabular}{l|l|l|l|l|l}
  \toprule
  \multicolumn{2}{c}{\textbf{Linear kernel}} &
  \multicolumn{2}{c}{\textbf{Polynomial kernel}} &
  \multicolumn{2}{c}{\textbf{Radial kernel}} \\
  \cmidrule{1-2} \cmidrule{3-4} \cmidrule{5-6}
  \makecell{\textbf{Default}\\\textbf{parameters}} &
  \makecell{\textbf{Setting}\\\textbf{parameters}} &
  \makecell{\textbf{Default}\\\textbf{parameters}} &
  \makecell{\textbf{Setting}\\\textbf{parameters}} &
  \makecell{\textbf{Default}\\\textbf{parameters}} &
  \makecell{\textbf{Setting}\\\textbf{parameters}} \\ 
  \midrule
  \color{red}{\textbf{\Sexpr{round(pROC::auc(roc.linear), 4)}}} &
  \Sexpr{round(pROC::auc(roc.linear_tune), 4)} &
  \textbf{\Sexpr{round(pROC::auc(roc.poly), 4)}} &
  \Sexpr{round(pROC::auc(roc.poly_tune), 4)} &
  \textbf{\Sexpr{round(pROC::auc(roc.radial), 4)}} &
  \Sexpr{round(pROC::auc(roc.radial_tune), 4)} \\
  \bottomrule
 \end{tabular}
\end{table}

We see in Table \ref{tab:aucs} that for all the kernels the best, slightly,
results are obtained with the default parameters. The setting parameters was
obtained with the training dataset and the AUC's presented in Table \ref{tab:aucs}
was obtained with the testing dataset. This means that that the setting parameters
generate the best results for the training data, not for the testing (in this
case, with this dataset). Neverthless, the AUC's are very similar. The best AUC is
obtained with the linear kernel (but the difference to the worst is of only
0.0117).

\hfill \(\blacksquare\)

\horrule{.5pt}

\vspace{\fill}

\horrule{1pt} \\

\end{document}