### Academic courses

***

<h4>[Extensions of regression models](https://github.com/mynameislaure/emr15)</h4>

* <h5>Piecewise regression</h5>
    + <h5>[Henrique](emr15/piecewise/)</h5>
    + <h5>[Eduardo](emr15/piecewise/piecewise.html)</h5>

* <h5>[Nonlinear models](emr15/nls/)</h5>

* <h5>Transformed likelihood</h5>
    + <h5>Henrique</h5>
        - <h5>[Theory](emr15/trans_likelihood/theory.html)</h5>
        - <h5>[Application](emr15/trans_likelihood/application.html)</h5>
    + <h5>[Eduardo](emr15/trans_likelihood/application-eduardojr.html)</h5>

* <h5>Mixed effect Models</h5>
    + <h5>[Poisson](emr15/lme/mixed_poisson_model.html)</h5>
    + <h5>[Piecewise](emr15/lme/piecewise_mixed_model.html)</h5>

* <h5>[Nonparametric regression](emr15/nonparametric/)</h5>

* <h5>Heteroscedastic regression models</h5>
    + <h5>[Theory](emr15/hetero/theory.html)</h5>
    + <h5>[Application](emr15/hetero/application.html)</h5>

***

<h4>[Markovian models](https://github.com/mynameislaure/ce064mm)</h4>

* <h5>[Hw 1](markov/hw1/master.pdf)</h5>

* <h5>[Hw 2](markov/hw2/master.pdf)</h5>

***

<h4>[Introduction to machine learning](https://github.com/mynameislaure/ce062)</h4>

+ <h5>[Gradient descent](intro2ml/gradient_descent/)</h5>

+ <h5>[Regularization](intro2ml/regularization/)</h5>

+ <h5>[Resampling methods](intro2ml/resampling_methods/)</h5>

+ <h5>[Supervisioned classification methods](intro2ml/supervisioned_classification_methods/)</h5>

+ <h5>[Support Vector Machine](intro2ml/support_vector_machine/)</h5>

+ <h5>[Tree based methods](intro2ml/tree_based_methods/)</h5>

+ <h5>[Text mining](intro2ml/text_mining/)</h5>

+ <h5>[Kobe Bryant shot selection](intro2ml/kobe_bryant_shot_selection/)</h5>

***

<h4>[Machine learning](https://github.com/mynameislaure/ML-UFMG)</h4>

* <h5>[Hw 1](ml/hw1/master.pdf)</h5>

* <h5>[Hw 2](ml/hw2/master.pdf)</h5>

* <h5>[Hw 3](ml/hw3/master.pdf)</h5>

* <h5>[Hw 4](ml/hw4/master.pdf)</h5>

* <h5>[Article presentation](ml/article/master.pdf)</h5>

* <h5>[Poster](ml/poster/master.pdf)</h5>

***

<h4>[Statistical methods](https://github.com/mynameislaure/mi404-statistical_methods)</h4>

* <h5>[Hw 1](stat_methods/hw1.pdf)</h5>

* <h5>[Hw 2](stat_methods/hw2.pdf)</h5>

***

<h4>[Computational methods in Statistics](cms/)</h4>

***

<h4>[Applied Statistics and data analysis](https://github.com/mynameislaure/amcs210)</h4>

* <h5>[Hw 1](applied_stats/hw1.pdf)</h5>

* <h5>[Hw 2](applied_stats/hw2.pdf)</h5>

* <h5>[Hw 3](applied_stats/hw3.pdf)</h5>

* <h5>[Midterm 1: Take-Home Part](applied_stats/md1-thp.pdf)</h5>

* <h5>[Project](applied_stats/project.pdf)</h5>

***

<h4>Nonparametric Statistics</h4>

> <h5>STAT 260. Master level course at [KAUST](https://www.kaust.edu.sa/en)
      offered by Professor [Ying Sun](https://www.kaust.edu.sa/en/study/faculty/ying-sun)
      in the Spring of 2018</h5>

* <h5>[Hw 1](nonparametric_stat/hw1.pdf) ([Rnw](nonparametric_stat/hw1.Rnw))</h5>

* <h5>[Hw 2](nonparametric_stat/hw2.pdf) ([Rnw](nonparametric_stat/hw2.Rnw))</h5>

* <h5>[Hw 3](nonparametric_stat/hw3.pdf) ([Rnw](nonparametric_stat/hw3.Rnw))</h5>

* <h5>[Hw 4](nonparametric_stat/hw4.pdf) ([Rnw](nonparametric_stat/hw4.Rnw))</h5>

* <h5>[Hw 5](nonparametric_stat/hw5.pdf) ([Rnw](nonparametric_stat/hw5.Rnw))</h5>

* <h5>Project</h5>
    + <h5>[Presentation](nonparametric_stat/project_slides.pdf)
          ([Rmd](nonparametric_stat/project_slides.Rmd),
           [template](nonparametric_stat/slides_template.tex))</h5>
    + <h5>[Report](nonparametric_stat/project_report.pdf)
          ([Rnw](nonparametric_stat/project_report.Rnw))</h5>

***

<h4>[Machine Learning](https://sites.google.com/site/kaust229machinelearning/)</h4>

* <h5>[Hw 1](ml-kaust/hw1.pdf) ([Rnw](ml-kaust/hw1.Rnw))</h5>

* <h5>[Hw 2](ml-kaust/hw2.pdf) ([Rnw](ml-kaust/hw2.Rnw))</h5>

* <h5>[Hw 3](ml-kaust/hw3.pdf) ([Rnw](ml-kaust/hw3.Rnw))</h5>

* <h5>[Hw 4](ml-kaust/hw4.pdf) ([Rnw](ml-kaust/hw4.Rnw))</h5>

* <h5>[Hw 5](ml-kaust/hw5.pdf) ([Rnw](ml-kaust/hw5.Rnw))</h5>

* <h5>[Hw 6](ml-kaust/hw6.pdf) ([Rnw](ml-kaust/hw6.Rnw))</h5>

* <h5>[Hw 7](ml-kaust/hw7.pdf) ([Rnw](ml-kaust/hw7.Rnw))</h5>

* <h5>[Hw 8](ml-kaust/hw8.pdf) ([Rnw](ml-kaust/hw8.Rnw))</h5>

* <h5>[Hw 9](ml-kaust/hw9.pdf) ([Rnw](ml-kaust/hw9.Rnw))</h5>

* <h5>[Hw 10](ml-kaust/hw10.pdf) ([Rnw](ml-kaust/hw10.Rnw))</h5>

* <h5>Project</h5>
    + <h5>[Report](ml-kaust/project_report.pdf)
          ([Rnw](ml-kaust/project_report.Rnw))</h5>

***

<h4>Numerical Optimization</h4>

> <h5>AMCS 211. Master level course at [KAUST](https://www.kaust.edu.sa/en)
      offered by Professor [Bernard Ghanem](http://www.bernardghanem.com/)
      in the Spring of 2018</h5>

* <h5>Coding part, [Hw 2](num_optim/hw2.pdf) ([Rnw](num_optim/hw2.Rnw))</h5>

* <h5>Coding part, [Hw 3](num_optim/hw3.pdf) ([Rnw](num_optim/hw3.Rnw)**</h5>

***

<h4>Numerical Analysis</h4>

> <h5>MNUM 7009. Graduate level course at [UFPR](https://www.ufpr.br)
      offered by Professor [Luiz Matioli](https://docs.ufpr.br/~matioli/)
      in the 2nd Semester of 2019</h5>

* <h5>Coding part, [Hw 1](numerical_analysis/list_1.pdf)</h5>

* <h5>Coding part, [Hw 2](numerical_analysis/list_2.pdf)</h5>

***

<h4>Computational Methods to Statistical Inference</h4>

> <h5>MNUM 7095. Graduate level course at [UFPR](https://www.ufpr.br)
      offered by Professor
      [Paulo Justiniano](http://leg.ufpr.br/~paulojus/)
      in the 2nd Semester of 2019</h5>

* <h5>[Hw 1](mcie/list_1.pdf)</h5>

***

<h4>[Return to main page](http://leg.ufpr.br/~henrique/)</h4>

***
