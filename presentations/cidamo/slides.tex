\documentclass[ignorenonframetext,]{beamer}

\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}

\beamertemplatenavigationsymbolsempty
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi

% Start adding some content
\usepackage{graphicx}
\usepackage{color}
\usepackage{beamerthemebars}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{changepage}
\usepackage{bm}
\usepackage{animate}
\usepackage{pifont}
\usepackage{framed}

\definecolor{shadecolor}{rgb}{1, .8, .3}


\usetheme{Boadilla}
\usecolortheme{dove}

%redefined colors for beamer
% \definecolor{beamer@UIUCblue}{RGB}{29,38,57}
\definecolor{beamer@UIUCblue}{RGB}{0,128,255}
% \definecolor{beamer@UIUCorange}{RGB}{215,85,54}
% \definecolor{beamer@UIUCorange}{RGB}{230,120,23}
\definecolor{beamer@UIUCorange}{RGB}{255,127,0}
% taken from
% http://identitystandards.illinois.edu/graphicstandardsmanual/generalguidelines/colors.html

\definecolor{beamer@UIUCgray}{RGB}{210,210,210}
\definecolor{beamer@UIUCgray2}{RGB}{244,244,244}

\definecolor{beamer@henrique}{rgb}{1,.8,.3}

% \setbeamercolor{frametitle}{fg=beamer@UIUCblue,bg=beamer@UIUCgray2}
\setbeamercolor{frametitle}{fg=black,bg=white}
\setbeamercolor{normal text}{fg=black}
% \setbeamercolor{title}{fg=beamer@UIUCblue,bg=beamer@UIUCgray2}
\setbeamercolor{title}{fg=black,bg=beamer@henrique}
\setbeamercolor{item projected}{fg=black,bg=beamer@UIUCgray2}

\setbeamertemplate{itemize items}{>>}
\setbeamertemplate{enumerate items}{>>}

\setbeamercolor{itemize item}{fg=beamer@UIUCorange}
\setbeamercolor{itemize subitem}{fg=beamer@UIUCorange}
\setbeamercolor{enumerate item}{fg=beamer@UIUCorange}
\setbeamercolor{enumerate subitem}{fg=beamer@UIUCorange}

% Boxes
\setbeamercolor{block title}{fg=beamer@UIUCblue,bg=beamer@UIUCorange}
\setbeamercolor{block body}{fg=blue,bg=beamer@UIUCblue!80}
% \setbeamercolor{title in head/foot}{fg=beamer@UIUCblue,bg=beamer@UIUCgray}
\setbeamercolor{title in head/foot}{fg=white,bg=white}
% \setbeamercolor{author in head/foot}{fg=white,bg=beamer@UIUCblue}
\setbeamercolor{author in head/foot}{fg=white,bg=white}
\setbeamercolor{institute in head/foot}{fg=white,bg=beamer@UIUCorange}
% \setbeamercolor{date in head/foot}{fg=white,bg=beamer@UIUCorange}
\setbeamercolor{date in head/foot}{fg=black,bg=white}
% \setbeamercolor{section in head/foot}{fg=white,bg=beamer@UIUCblue}
\setbeamercolor{section in head/foot}{fg=black,bg=white}
% \setbeamercolor{subsection in head/foot}{fg=white,bg=beamer@UIUCorange}
\setbeamercolor{subsection in head/foot}{fg=black,bg=white}

\hypersetup{colorlinks=true,urlcolor=beamer@UIUCblue,linkcolor=beamer@UIUCblue,% link color controls section, subsection, and title
citecolor = beamer@UIUCorange,
anchorcolor = beamer@UIUCorange}

%override title link color
\addtobeamertemplate{headline}{\hypersetup{linkcolor=.}}{}
\addtobeamertemplate{footline}{\hypersetup{linkcolor=.}}{}

% Setup blocks
\setbeamercolor{block title}{fg = white, bg = beamer@UIUCblue}
\setbeamercolor{block body}{fg=black,bg=beamer@UIUCgray2}

\setbeamercolor{block title alerted}{fg = white, bg = beamer@UIUCorange}
\setbeamercolor{block body alerted}{fg=black,bg=beamer@UIUCgray2}

\setbeamercolor{block title example}{fg = beamer@UIUCblue, bg = beamer@UIUCgray}
\setbeamercolor{block body example}{fg=black,bg=beamer@UIUCgray2}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight0.8\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}

% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom

\AtBeginSection[]
{
  \ifbibliography
  \else
    \let\insertsectionnumber\relax
    \let\sectionname\relax
    \begin{frame}
      \frametitle{On the Agenda}
      % \begin{multicols}{2}
      % \tableofcontents[currentsection]
      \tableofcontents
      % \end{multicols}
    \end{frame}
  \fi
}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

\author[
leg.ufpr.br/\textasciitilde{}henrique
]{Henrique Laureano \newline \url{http://leg.ufpr.br/~henrique}}
\date[
leg.ufpr.br/\textasciitilde{}henrique
]{
\href{https://cidamo.github.io/CiDWeek/}{CiDWeek I}, 03-07/02/2020
}

% Include logos
\titlegraphic{
  \includegraphics[width=.175\textwidth]{logo/leg.pdf}
  \hspace{.5\textwidth}
  \includegraphics[width=.25\textwidth]{logo/ufpr.pdf}
  % \includegraphics[width=.175\textwidth]{logo/leg.pdf}
  % \hspace{.125\textwidth}
  % \includegraphics[width=.25\textwidth]{logo/ufpr.pdf}
  % \hspace{.125\textwidth}
  % \includegraphics[width=.25\textwidth]{logo/cidamo.png}
}

\logo{\includegraphics[width=.1\textwidth]{logo/leg.pdf}}
% \logo{\includegraphics[width=.15\textwidth]{logo/cidamo.png}}

% Option to fake out the raw_tex plugin and, thus, enabling the embedding of
% markdown within a column scheme.
% See:
% (1) https://groups.google.com/forum/#!msg/pandoc-discuss/vcy7v9Uk95U/LDgWJTHTRR4J
% (2) http://stackoverflow.com/questions/15142134/slides-with-columns-in-pandoc
\def\begincols{\begin{columns}}
\def\endcols{\end{columns}}

\begin{document}

% Necessary due to the ignorenonframetext requirement
% See: http://tex.stackexchange.com/questions/181032/ignorenonframetext-option-breaks-frame-background-color-option
\mode<all>{
\title[
Missing ``\texttt{short-title}'' field!
]{
% \begin{columns}
% \column{.15\textwidth}
% \hspace{.2in}
% \vspace{.1in}
% \includegraphics{leg.pdf}
% \column{.85\textwidth}
Naive Bayes \& Regress\(\~{a}\)o Log\(\'{i}\)stica
% \end{columns}
}
}
\mode*

% plain is to remove the \logo from the title page
\frame[plain]{\titlepage}


\begin{frame}{Naive Bayes}
\protect\hypertarget{naive-bayes}{}

Primeiro, precisamos falar sobre o que \(\'{e}\) um
\textcolor{beamer@UIUCorange}{classificador de Bayes}.

\begin{block}{Classificador de Bayes}
 Um classificador probabil\(\'{i}\)stico  baseado no
 \textcolor{beamer@UIUCorange}{teorema de Bayes}.
\end{block}

\noindent{\color{beamer@UIUCblue}Exemplo,~\rule{.85\linewidth}{0.25mm}}

\begin{itemize}
\item
  Meningite causa torcicolo 50\% das vezes,
  \textcolor{beamer@UIUCorange}{\(\mathbb{P}[T | M]\)}
\item
  Prob. \emph{a priori} de um paciente estar com meningite \(\'{e}\)
  1/50.000, \textcolor{beamer@UIUCorange}{\(\mathbb{P}[M]\)}
\item
  Probabilidade \emph{a priori} de um paciente estar com torcicolo
  \(\'{e}\) 1/20, \textcolor{beamer@UIUCorange}{\(\mathbb{P}[T]\)}
\end{itemize}

\begin{minipage}{.9\linewidth}
 Se um paciente est\(\'{a}\) com torcicolo, qual a probabilidade dele
 estar com meningite?
 \[ \textcolor{beamer@UIUCorange}{\mathbb{P}[M | T]} =
    \frac{\mathbb{P}[T | M]~\mathbb{P}[M]}{\mathbb{P}[T]} =
    \frac{1/2 \times 1/50.000}{1/20} = 0.0002.
 \]
\end{minipage}

\end{frame}

\begin{frame}{Classificadores Bayesianos}
\protect\hypertarget{classificadores-bayesianos}{}

Considere \textcolor{beamer@UIUCorange}{atributos}
\(A_{1}, A_{2}, \dots A_{n}\) e uma
\textcolor{beamer@UIUCorange}{classe} \(C\) com r\(\'{o}\)tulos
\(c_{1}, c_{2}, \dots c_{k}\).

O que queremos? \[ \text{Predi\c{c}\~{a}o}: \quad
   C = c_{1} \text{ ou } C = c_{2} \text{ ou } \dots, \] i.e., queremos
o valor de \(C\) que maximiza
\(\mathbb{P}[C | A_{1}, A_{2}, \dots, A_{n}]\).

\begin{minipage}{.85\linewidth}
 \begin{block}{Como fazemos? Teorema de Bayes.}
  Calculamos a probabilidade \textit{a posteriori}
  \(\mathbb{P}[C | A_{1}, A_{2}, \dots, A_{n}]\) para todos os valores de
  \(C\),
  \[ \mathbb{P}[C_{k} | A_{1}, A_{2}, \dots, A_{n}] =
     \frac{\mathbb{P}[A_{1}, A_{2}, \dots, A_{n} | C_{k}]~
           \mathbb{P}[C_{k}]}{
                              \mathbb{P}[A_{1}, A_{2}, \dots, A_{n}]
                             }.
  \]
 \end{block}
\end{minipage}

\noindent{\color{beamer@UIUCorange}\rule{.85\linewidth}{0.25mm}}

E como calculamos \(\mathbb{P}[A_{1}, A_{2}, \dots, A_{n} | C_{k}]\)?
\textcolor{beamer@UIUCorange}{Naive Bayes}.

\end{frame}

\begin{frame}{Classificador Naive Bayes}
\protect\hypertarget{classificador-naive-bayes}{}

\begin{block}{Por que \textit{naive}?}
 Porque se assume \textcolor{beamer@UIUCorange}{independ\(\^{e}\)ncia}
 entre os atributos \(A_{i }\) \underline{dado} uma classe, i.e.,
 \[ \mathbb{P}[A_{1}, A_{2}, \dots, A_{n} | C_{k}] =
    \mathbb{P}[A_{1} | C_{k}]~
    \mathbb{P}[A_{2} | C_{k}]~
    \dots~
    \mathbb{P}[A_{n} | C_{k}].
 \]
\end{block}

Vantagem: \underline{Grande} redu\(\c{c}\~{a}\)o do custo computational.

Um novo ponto \(\'{e}\) classificado como \(C_{k}\) se
\(\mathbb{P}[C_{k}] \times \prod_{i=1}^{n} \mathbb{P}[A_{i} | C_{k}]\)
\(\'{e}\) m\(\'{a}\)ximo.

\noindent{\color{beamer@UIUCorange}i.e.,~\rule{.95\linewidth}{0.25mm}}

\[ C_{k} = \underset{k \in \{1, \dots, K\}}{\text{argmax}}
           \mathbb{P}[C_{k}] \times
           \prod_{i=1}^{n} \mathbb{P}[A_{i} | C_{k}]
\]

\end{frame}

\begin{frame}{Exemplo: Estimando probabilidades a partir dos dados}
\protect\hypertarget{exemplo-estimando-probabilidades-a-partir-dos-dados}{}

\begin{columns}
 \begin{column}{.5\textwidth}
  \includegraphics[width=\linewidth]{naive_bayes-example.png}
 \end{column}
 \begin{column}{.5\textwidth}
  \begin{itemize}
   \item \(\mathbb{P}[C] = N_{k} / N\)

    \begin{itemize}
     \item \(\mathbb{P}[C = \text{No}] = 7 / 10\)
     \item \(\mathbb{P}[C = \text{Yes}] = 3 / 10\)
    \end{itemize}
  \end{itemize}

  \noindent{\color{beamer@UIUCblue}
            Atributos discretos,~\rule{.45\linewidth}{0.25mm}}

  \begin{itemize}
   \item \(\mathbb{P}[A_{i} | C_{k}] = A_{ik} / N_{k}\)

    \begin{itemize}
     \item \(\mathbb{P}[\text{Status} = \text{Married} | \text{No}] =
             4 / 7\)
     \item \(\mathbb{P}[\text{Refund} = \text{Yes} | \text{Yes}] = 0\)
     \item \(\dots\)
    \end{itemize}

  \end{itemize}
 \end{column}
\end{columns}

\end{frame}

\begin{frame}{E com atributos cont\(\'{i}\)nuos?}
\protect\hypertarget{e-com-atributos-continuos}{}

\begin{columns}
 \begin{column}{.4\textwidth}
  \includegraphics[width=\linewidth]{naive_bayes-example.png}
 \end{column}
 \begin{column}{.6\textwidth}
  \begin{block}{Estima\(\c{c}\~{a}\)o da densidade de probabilidade}
   \begin{itemize}
    \item Se assume distribui\(\c{c}\~{a}\)o Normal

    \item Se estima a m\(\'{e}\)dia \(\mu\) e o desvio padr\(\~{a}\)o
          \(\sigma\)

    \item Se estima a probabilidade condicional
     \[ \mathbb{P}[A_{i} | C_{k}] =
        \frac{\exp \left\{-\frac{(A_{i} - \mu_{ik})^{2}}{2\sigma_{ik}^{2}}
                   \right\}}{\sqrt{2\pi\sigma_{ik}^{2}}}
     \]
   \end{itemize}
  \end{block}
 \end{column}
\end{columns}

\noindent{\color{beamer@UIUCorange}Exemplo,~\rule{.75\linewidth}{0.25mm}}
\vspace{-.25cm}

\begin{minipage}{.85\linewidth}
 \[ \begin{aligned}
     \mathbb{P}[\text{Income} = 120 | \text{No}] &=
     \frac{1}{\sqrt{2\pi 2975}}
     \exp \left\{-\frac{(120 - 110)^{2}}{2\times 2975}\right\}\\
     &= 0.0072.
    \end{aligned} \]
\end{minipage}

\end{frame}

\begin{frame}{Classificador Naive Bayes: Exemplo}
\protect\hypertarget{classificador-naive-bayes-exemplo}{}

\begin{block}{Dado o perfil:
              \(X\) = (Refund = No, Married, Income = 120k)}
 \[ \begin{aligned}
     \mathbb{P}[X | \text{Class} = \text{No}] =
     ~&\mathbb{P}[\text{Refund} = \text{No} | \text{Class} = \text{No}]
       ~\times\\
      &\mathbb{P}[\text{Married} | \text{Class} = \text{No}]
       ~\times\\
      &\mathbb{P}[\text{Income} = 120k | \text{Class} = \text{No}]\\
   = ~& 4/7 \times 4/7 \times 0.0072 = 0.0024.
    \end{aligned}
 \]
 \[ \begin{aligned}
     \mathbb{P}[X | \text{Class} = \text{Yes}] =
     ~&\mathbb{P}[\text{Refund} = \text{No} | \text{Class} = \text{Yes}]
       ~\times\\
      &\mathbb{P}[\text{Married} | \text{Class} = \text{Yes}]
       ~\times\\
      &\mathbb{P}[\text{Income} = 120k | \text{Class} = \text{Yes}]\\
   = ~& 1 \times 0 \times 10^{-9} = 0.
    \end{aligned}
 \]
\end{block}
\vspace{-.3cm}

\noindent{\color{beamer@UIUCorange}\rule{\linewidth}{0.25mm}}

J\(\'{a}\) que
\(\mathbb{P}[X | \text{No}]~\mathbb{P}[\text{No}] >  \mathbb{P}[X | \text{Yes}]~\mathbb{P}[\text{Yes}]\),
\[ \Rightarrow \quad
   \mathbb{P}[X | \text{No}] > \mathbb{P}[X | \text{Yes}]
   \Rightarrow
   \textcolor{beamer@UIUCorange}{\text{Class} = \text{No}}.
\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section}{}

\begin{block}{Problema de probabilidade zero}
 Se uma das probabilidades condicionais \(\'{e}\) zero, ent\(\~{a}\)o
 toda a express\(\~{a}\)o
 \[ \mathbb{P}[A_{1}, A_{2}, \dots, A_{n} | C_{k}] =
    \prod_{i=1}^{n} \mathbb{P}[A_{i} | C_{k}], \text{ se torna zero.}
 \]
\end{block}

Como evitamos isso?

Abordagens: \[ \text{Original}: \quad \mathbb{P}[A_{i} | C_{k}] =
   \frac{N_{ik}}{N_{k}}, \qquad
   \textcolor{beamer@UIUCorange}{\text{Laplace}}: \quad
   \mathbb{P}[A_{i} | C_{k}] = \frac{N_{ik} + 1}{N_{k} + k},
\] \[ \text{Estimativa-M}: \quad \mathbb{P}[A_{i} | C_{k}] =
   \frac{N_{ik} + mp}{N_{k} + m},
\] em que \(p\) \(\'{e}\) uma probabilidade \emph{a priori} e \(m\)
\(\'{e}\) um par\(\^{a}\)metro.
\noindent{\color{beamer@UIUCblue}\rule{.8\linewidth}{0.25mm}}

Qual a abordagem \(\'{e}\) mais utilizada? \(\newline\)
Corre\(\c{c}\~{a}\)o de \textcolor{beamer@UIUCorange}{Laplace} (ou
estimador de Laplace).

\end{frame}

\begin{frame}{Classificador Naive Bayes: Coment\(\'{a}\)rios}
\protect\hypertarget{classificador-naive-bayes-comentarios}{}

\noindent{\color{beamer@UIUCblue}Vantagens,~\rule{.5\linewidth}{0.25mm}}

\begin{itemize}
 \item F\(\'{a}\)cil de implementar

 \item Apresenta bons resultados na maioria dos cen\(\'{a}\)rios

 \item Robusto com \textit{outliers} e atributos irrelevantes

 \item Ignora dados faltantes durante o c\(\'{a}\)lculo das
       probabilidades
\end{itemize}

\noindent{\color{beamer@UIUCblue}Desvantagens,~\rule{.5\linewidth}{0.25mm}}

\begin{itemize}
 \item Suposi\(\c{c}\~{a}\)o de
       \textcolor{beamer@UIUCorange}{independ\(\^{e}\)ncia}

 \item Perda de acur\(\'{a}\)cia
\end{itemize}

\begin{minipage}{.825\linewidth}
 \begin{block}{Como lidar com essa depend\(\^{e}\)ncia?}
  \textcolor{beamer@UIUCorange}{Redes Bayesianas}: Um modelo
  gr\(\'{a}\)fico baseado em vari\(\'{a}\)veis condicionalmente
  independentes.
 \end{block}
\end{minipage}

\end{frame}

\begin{frame}{Regress\(\~{a}\)o Log\(\'{i}\)stica}
\protect\hypertarget{regressao-logistica}{}

\begin{minipage}{.5\linewidth}
 \begin{block}{Contexto}
  \[ \text{Regress\~{a}o}: \quad Y = X \beta + \epsilon. \]
 \end{block}
\end{minipage}

Log\(\'{i}\)stica? Quando? Quando \(Y\) \(\'{e}\)
\textcolor{beamer@UIUCorange}{qualitativa}.

\noindent
{\color{beamer@UIUCblue}Ideia!
E se n\(\'{o}\)s codificarmos \(Y\)?~\rule{.5\linewidth}{0.25mm}}

Assim podemos continuar usando a regress\(\~{a}\)o linear usual, e.g.,
\(\newline\) Queremos saber o que ocorreu com um paciente com base em
seus sintomas

\[ Y = \begin{cases}
        1 & \text{se overdose de drogas}\\
        2 & \text{se ataque epil\'{e}tico}
      \end{cases}
\]

\begin{minipage}{.5\linewidth}
 Problema! \(\newline\)
 Este tipo de codifica\(\c{c}\~{a}\)o implica num ordenamento das
 respostas.
\end{minipage}

\end{frame}

\begin{frame}{Por que usar Regress\(\~{a}\)o Log\(\'{i}\)stica?}
\protect\hypertarget{por-que-usar-regressao-logistica}{}

\begin{columns}
 \begin{column}{.25\linewidth}
  \centering
  \includegraphics[width=.8\linewidth]{roll_safe.png}
 \end{column}
 \begin{column}{.75\linewidth}
  Ok, mas e se \(Y\) tiver uma ordena\(\c{c}\~{a}\)o natural? \(\newline\)
  e.g., leve, moderado e severo.
 \end{column}
\end{columns}

Se \(Y\) for bin\(\'{a}\)ria a regress\(\~{a}\)o linear at\(\'{e}\) que
funciona.

\begin{itemize}
\tightlist
\item
  Contudo, as predi\(\c{c}\~{o}\)es podem ficar fora do intervalo
  \([0, 1]\).
\end{itemize}

\noindent{\color{beamer@UIUCblue}\rule{\linewidth}{0.25mm}}

\begin{minipage}{.75\linewidth}
 Por raz\(\~{o}\)es como esta que \(\'{e}\) prefer\(\'{i}\)vel o uso
 de m\(\'{e}\)todos de classifica\(\c{c}\~{a}\)o pr\(\'{o}\)prios
 para vari\(\'{a}\)veis qualitativas.
 \[ \text{M\'{e}todos de classifica\c{c}\~{a}o pr\'{o}prios? }
    \text{\textcolor{beamer@UIUCorange}{Regress\~{a}o Log\'{i}stica}}.
 \]
\end{minipage}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-1}{}

Regress\(\~{a}\)o Linear \(\times\) Regress\(\~{a}\)o Log\(\'{i}\)stica

\footnotesize\includegraphics{slides_files/figure-beamer/unnamed-chunk-2-1.pdf}
\normalsize

\noindent{\color{beamer@UIUCorange}\rule{\linewidth}{0.25mm}}

\[ \text{De onde vem esta forma em } S?
   \textcolor{beamer@UIUCorange}{\text{ fun\c{c}\~{a}o log\'{i}stica}}:
   \frac{e^{X\beta}}{1+e^{X\beta}}.
\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-2}{}

\begin{columns}
 \begin{column}{.3\linewidth}
  \centering
  \includegraphics[width=.95\linewidth]{rambo.jpg}
 \end{column}
 \begin{column}{.7\linewidth}
  Ok, mas onde e como se usa essa
  \textcolor{beamer@UIUCorange}{fun\c{c}\~{a}o log\'{i}stica}?
 \end{column}
\end{columns}

Num modelo de regress\(\~{a}\)o temos
\(\mathbb{E}[Y | X] = \mu = g^{-1}(X \beta)\).

\begin{itemize}
\item
  No caso Normal, \(g\) \(\'{e}\) uma fun\(\c{c}\~{a}\)o identidade.
  \(\newline\) O que configura a regress\(\~{a}\)o linear que todos
  conhecemos, \(Y = X\beta + \epsilon\).
\item
  Se assumida uma distribui\(\c{c}\~{a}\)o diferente da Normal para
  \(Y | X\), \(g\) ser\(\'{a}\) diferente da fun\(\c{c}\~{a}\)o
  identidade e assim teremos o que configura os chamados GLMs.
\end{itemize}

\noindent{\color{beamer@UIUCorange}\rule{\linewidth}{0.25mm}}

\begin{minipage}{.7\linewidth}
 \begin{block}{Regress\(\~{a}\)o Log\(\'{i}\)stica}
  Se \(Y\) for dicot\(\^{o}\)mica e \(g\) for a fun\(\c{c}\~{a}\)o
  log\(\'{i}\)stica, \(\newline\)
  ent\(\~{a}\)o temos uma regress\(\~{a}\)o log\(\'{i}\)stica.
 \end{block}
\end{minipage}

\end{frame}

\begin{frame}{Interpreta\(\c{c}\~{a}\)o?}
\protect\hypertarget{interpretaccao}{}

\begin{center}
\includegraphics[width=.8\linewidth]{logistic-relations.jpg}
\end{center}
\vspace{1.25cm}

\end{frame}

\begin{frame}{Interpreta\(\c{c}\~{a}\)o? Raz\(\~{a}\)o de chances}
\protect\hypertarget{interpretaccao-razao-de-chances}{}

\noindent{\color{beamer@UIUCorange}Chances,~\rule{.8\linewidth}{0.25mm}}
\[
 \text{chance}(X) = e^{X\beta} = \frac{g(X\beta)}{1 - g(X\beta)}.
\] e.g.,
\[ g(X\beta) = 0.2 \Rightarrow \frac{0.2}{1-0.2} = \frac{1}{4}, \quad
    g(X\beta) = 0.9 \Rightarrow \frac{0.9}{1-0.9} = 9.
 \] \noindent
{\color{beamer@UIUCorange}Raz\(\~{a}\)o de chances,~\rule{.675\linewidth}{0.25mm}}

Para uma vari\(\'{a}\)vel cont\(\'{i}\)nua: \[
 \frac{\text{chance}(x+1)}{\text{chance}(x)} =
 \frac{e^{\beta_{0}+\beta_{1}(x+1)}}{e^{\beta_{0}+\beta_{1}x}} =
 e^{\beta_{1}}.
\]

\end{frame}

\begin{frame}{M\(\'{a}\)xima verossimilhan\(\c{c}\)a}
\protect\hypertarget{maxima-verossimilhancca}{}

\noindent
{\color{beamer@UIUCorange}O qu\(\^{e}\)?~\rule{.75\linewidth}{0.25mm}}

Fun\(\c{c}\~{a}\)o de verossimilhan\(\c{c}\)a \(\'{e}\) o nome dado a
fun\(\c{c}\~{a}\)o que precisamos
\textcolor{beamer@UIUCorange}{maximizar}.

\begin{minipage}{.6\linewidth}
 \begin{block}{Verossimilhan\(\c{c}\)a}
  \[ L(\beta) = \prod_{i: Y_{i}=1} g(X_{i}\beta)
                \prod_{i': Y_{i'}=0} (1 - g(X_{i}\beta))
  \]
 \end{block}
\end{minipage}

\noindent
{\color{beamer@UIUCorange}Por qu\(\^{e}\)?~\rule{.75\linewidth}{0.25mm}}

Queremos estimativas para \(\beta\), e tais estimativas s\(\~{a}\)o
obtidas via a maximiza\(\c{c}\~{a}\)o de \(L(\beta)\).

\noindent
{\color{beamer@UIUCorange}Como?~\rule{.7\linewidth}{0.25mm}}
\vspace{.1cm}

\begin{minipage}{.8\linewidth}
 \(L(\beta)\) \(\'{e}\) uma fun\(\c{c}\~{a}\)o "qualquer" que queremos
 otimizar. \(\newline\)
 Dependendo da fun\(\c{c}\~{a}\)o uma solu\(\c{c}\~{a}\)o
 anal\(\'{i}\)tica pode n\(\~{a}\)o existir, e a\(\'{i}\) m\(\'{e}\)todos
 num\(\'{e}\)ricos se fazem necess\(\'{a}\)rio.
\end{minipage}

\end{frame}

\begin{frame}[fragile]{Software: \texttt{R}}
\protect\hypertarget{software}{}

\noindent
{\color{beamer@UIUCorange}Naive Bayes,~\rule{.55\linewidth}{0.25mm}}

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(e1071)}

\NormalTok{modelo <-}\StringTok{ }\KeywordTok{naiveBayes}\NormalTok{(Y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\NormalTok{x3, }\DataTypeTok{data =}\NormalTok{ dados)}
\NormalTok{## ou}
\NormalTok{modelo <-}\StringTok{ }\KeywordTok{naiveBayes}\NormalTok{(Y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ dados)}
\NormalTok{## se Y, x1, x2 e x3 forem todas as colunas de "dados"}
\end{Highlighting}
\end{Shaded}

\normalsize

\noindent
{\color{beamer@UIUCorange}
 Regress\(\~{a}\)o Log\(\'{i}\)stica,~\rule{.6\linewidth}{0.25mm}}

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(Y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\NormalTok{x3,}
              \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ dados)}
\NormalTok{## ou}
\NormalTok{modelo <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(Y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ dados)}
\NormalTok{## se Y, x1, x2 e x3 forem todas as colunas de "dados"}
\end{Highlighting}
\end{Shaded}

\normalsize
\vspace{1.25cm}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-3}{}

\centering

\includegraphics[width=.95\linewidth]{thank_you.jpg}

\end{frame}

\end{document}
