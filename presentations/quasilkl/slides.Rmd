---
title: "QUASI-LIKELIHOOD FUNCTIONS"
subtitle: By Peter McCullagh, 1983
author: Henrique Laureano ([.github.io](https://henriquelaureano.github.io))
date: July 23, 2021
institute: LEG @ UFPR
classoption: [aspectratio=169]
output:
  beamer_presentation:
    includes:
      in_header: beamerheader.txt
---

###

\begin{columns}
 \column{3cm}
  \includegraphics[height=3cm]{logo/mccullagh_old.jpg}
 \column{12cm}
  \includegraphics[height=4.5cm]{
   logo/quasi_likelihood_functions-cover.png}
\end{columns}

\bigskip
\begin{columns}
 \column{3cm}
  \includegraphics[height=3cm]{logo/mccullagh_now.jpg}
 \column{12cm}
  \begin{enumerate}
   \item Distinguished Professor\\
         in the Department of Statistics @ University of Chicago;
   \vspace{0.15cm}
   \item Completed his PhD at Imperial College London,\\
         supervised by David Cox and Anthony Atkinson;
   \vspace{0.15cm}
   \item Also at Imperial College London,\\
         was the PhD supervisor of Gauss Cordeiro.
  \end{enumerate}
\end{columns}

# Introduction

### Introduction

\vspace{-0.1cm}
1. Likelihood fucntion with \textbf{exponential family form}\newline
   \hspace*{0.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
   MLE through \textbf{weighted least squares}

   - \textbf{variance (assumed) constant}:
     we minimize a sum of squared residuals;
   
   - \textbf{variance not constant}:\newline
     estimating equations can be thought as a generalization of the
     scoring method.

2. Likelihood function \textcolor{AlertOrange}{without} exponential
   family form\newline
   \hspace*{0.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
   In some cases: weighted least squares\newline
   \hspace*{1cm}\rotatebox[origin=c]{180}{$\Lsh$}
   Jorgensen, B. (1983). Maximum likelihood estimation and large sample
                         \newline
                         \hspace*{5.05cm}
                         inference for generalized linear and non-linear
                         \newline
                         \hspace*{5.05cm}
                         regression models. \textit{Biometrika} 70

\vspace{-0.1cm}
\begin{minipage}{14cm}
\begin{block}{Paper purposes}
 \begin{enumerate}
  \item Maximize the likelihood function through weighted least squares
        \newline
        \hspace*{.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
        In which class of problems;
  \item Weighted least squares under 2nd moment assumptions
        (\textbf{quasi-likelihood}).
 \end{enumerate}
\end{block}
\end{minipage}

# A class of likelihood functions

### A class of likelihood functions

\[
 \text{Log likelihood written in the form}: \qquad
 \sigma^{-2}\{\mathbf{y}^{\top}\bm{\theta} -
              \mathbf{b}(\bm{\theta}) - \mathbf{c}(\mathbf{y}, \sigma)\}
\]

\begin{center}
 \begin{minipage}{12.25cm}
  \begin{block}{The first two cumulants}
   By differentiating it and assuming that the support does not depend
   on \(\bm{\theta}\)\newline
   \hspace*{.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
   \(E(\mathbf{Y}) = \bm{\mu} = {\mathbf{b}}'(\bm{\theta})\) and
   \(\text{Cov}(\mathbf{Y}) = \sigma^{2}{\mathbf{b}}''(\bm{\theta})
                            = \sigma^{2}\mathbf{V}(\bm{\mu})\).
  \end{block}
 \end{minipage}
\end{center}

\bigskip
\begin{description}
 \item[In fact,] the \(r\)th order cumulants of \(\mathbf{Y}\) are given
                by \(\kappa_{r} = \sigma^{2r-2}
                                  \mathbf{b}^{(r)}(\bm{\theta})\).
\end{description}

\bigskip
\begin{enumerate}
 \item The first two cumulants describe the random component of the
       model;
 \item However, in applications it is usually the systematic or
       nonrandom variation that is of primary importance\newline
       \hspace*{0.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
       \(E(\mathbf{Y}) = \bm{\mu} = \bm{\mu}(\bm{\beta})\) or
       \(E\{(\mathbf{h}(\mathbf{Y}))\} = \bm{\psi}(\bm{\beta})\)
       (implicitly involving \(\sigma^{2}\)).
\end{enumerate}

### A class of likelihood functions

\begin{description}
 \item[If \(\sigma^{2}\) is known,] log-likelihood is an exponential
                                    family
  \vspace{0.15cm}\newline
  \hspace*{0.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
  variance and all higher order cumulants of \(\mathbf{Y}\) are\newline
  \hspace*{0.82cm}functions of the mean vector alone
  \vspace{0.15cm}\newline
  \hspace*{1cm}\rotatebox[origin=c]{180}{$\Lsh$}
  exponential, Poisson, multinomial, noncentral hypergeometric\newline
  \hspace*{1.31cm}and partial likelihoods (survival analysis)
  \vspace{0.15cm}\newline
  \hspace*{1.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
  MLE of \(\bm{\beta}\) through weighted least squares\newline
  \hspace*{2cm}\rotatebox[origin=c]{180}{$\Lsh$}
  \(\bm{\mu}\) and \(\sigma^{2}\) are orthogonal\newline
  \hspace*{2.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
  \(\bm{\beta}\) and \(\sigma^{2}\) also orthogonal;
 \bigskip
 \item[If \(\sigma^{2}\) is unknown,] log-likelihood is
          \textcolor{AlertOrange}{not generally} an exponential
          family\newline
          \hspace*{0.5cm}\rotatebox[origin=c]{180}{$\Lsh$}
          However, MLE of \(\bm{\beta}\) still through weighted least
          squares\newline
          \hspace*{1cm}\rotatebox[origin=c]{180}{$\Lsh$}
          \textcolor{UniBlue}{If}
          \(E(\mathbf{Y})\) does not involve \(\sigma^{2}\).
\end{description}

### A class of likelihood functions

\vspace{-0.25cm}
\begin{minipage}{13cm}
 \begin{block}{Least square equations}
  \[
   \def\hat{\mathaccent "705E\relax}
   \mathbf{D}^{\top}\mathbf{V}^{-}
   \{\mathbf{y} - \bm{\mu}(\hat{\bm{\beta}})\} = \mathbf{0}, \qquad
   \text{for the parameters in} \quad
   E(\mathbf{Y}) = \bm{\mu}(\bm{\beta})
  \]
  \begin{multicols}{2}
   \begin{itemize}
    \item \(\mathbf{D} = d\bm{\mu}/d\bm{\beta}, \quad N \times p\);
    \item \(\mathbf{V}^{-}\) is a generalized inverse of \(\mathbf{V}\).
   \end{itemize}
  \end{multicols}
  \vspace{-0.15cm}
  Why its name?
  \vspace{0.15cm}
  \begin{enumerate}
   \item \textbf{Geometrical interpretation}:
         projections of the residual vector
         \(\def\hat{\mathaccent "705E\relax}
           \mathbf{y} - \bm{\mu}(\hat{\bm{\beta}}_{0})\) on to the
         tangent space of the solution locus \(\bm{\mu}(\bm{\beta})\);
   \vspace{0.15cm}
   \item These equations \textbf{do not} depend on \(\sigma^{2}\).
  \end{enumerate}
 \end{block}
\end{minipage}

\vspace{-0.1cm}
\begin{center}
 \begin{minipage}{12cm}
  \begin{block}{Newton-Raphson method}
   We replace the second derivative matrix by its expected value,
   \(\mathbf{D}^{\top}\mathbf{V}^{-}\mathbf{D}\)
   \[
    \def\hat{\mathaccent "705E\relax}
    \hat{\bm{\beta}}_{1} - \hat{\bm{\beta}}_{0} =
    (\mathbf{D}^{\top}\mathbf{V}^{-}\mathbf{D})^{-1}
    \mathbf{D}^{\top}\mathbf{V}^{-}(\mathbf{y} - \hat{\bm{\mu}}_{0}).
   \]
  \end{block}
 \end{minipage}
\end{center}

# Quasi-likelihood functions

### Quasi-likelihood functions

\begin{center}
 \begin{minipage}{14.5cm}
  \begin{block}{Reversing the natural order of assumptions}
   \begin{enumerate}
    \item Instead of taking the log-likelihood to be of the exponential
          family form and \textcolor{AlertOrange}{then} deriving its
          moments;
          
   \vspace{0.15cm}
    \item We begin with the moments and \textcolor{AlertOrange}{then}
          attempt to reconstruct the log-likelihood.
   \end{enumerate}
   \vspace{0.3cm}
   \[
    \text{The reconstituted function is called a
    \textbf{quasi-likelihood}}.
   \]
  \end{block}
 \end{minipage}
\end{center}

# Properties of quasi-likelihood functions

### Simulation study model designs

\begin{columns}
 \column{5.75cm}
  \begin{block}{Risk model}
   Latent effects only on the risk level i.e.,
   \[
    \Sigma = \begin{bmatrix}
              \sigma_{u_{1}}^{2} & \text{cov}_{u_{1}, u_{2}}\\
                                 & \sigma_{u_{2}}^{2}
             \end{bmatrix}.
   \]
  \end{block}
 \column{5.75cm}
  \begin{block}{Time model}
   Latent effects only on the failure time trajectory level i.e.,
   \[
    \Sigma = \begin{bmatrix}
              \sigma_{\eta_{1}}^{2} & \text{cov}_{\eta_{1}, \eta_{2}}\\
                                    & \sigma_{\eta_{2}}^{2}
              \end{bmatrix}.
   \]
  \end{block}
\end{columns}

\begin{columns}
 \column{7cm}
  \begin{block}{Block-diag model}
   Latent effects on the risk and time levels without cross-correlations
   i.e.,
   \[
    \Sigma = \begin{bmatrix}
              \sigma_{u_{1}}^{2} & \text{cov}_{u_{1}, u_{2}} & 0 & 0\\
              & \sigma_{u_{2}}^{2} & 0 & 0\\
              & & \sigma_{\eta_{1}}^{2} & \text{cov}_{\eta_{1}, \eta_{2}}\\
              & & & \sigma_{\eta_{2}}^{2}
             \end{bmatrix}.
   \]
  \end{block}
 \column{7cm}
  \begin{block}{Complete model}
   A \textit{complete} latent effects structure\newline
   i.e.,
   \[
    \Sigma = \begin{bmatrix}
              \sigma_{u_{1}}^{2} &
              \text{cov}_{u_{1}, u_{2}} &
              \text{cov}_{u_{1}, \eta_{1}} & \text{cov}_{u_{1}, \eta_{2}}\\
              & \sigma_{u_{2}}^{2} &
              \text{cov}_{u_{2}, \eta_{1}} & \text{cov}_{u_{2}, \eta_{2}}\\
              & & \sigma_{\eta_{1}}^{2} & \text{cov}_{\eta_{1}, \eta_{2}}\\
              & & & \sigma_{\eta_{2}}^{2}
              \end{bmatrix}.
   \]
  \end{block}
\end{columns}

### Simulation study setup

\vspace{-0.3cm}
\begin{description}
 \item[Four] latent effects structures:
  \begin{multicols}{4}
   \begin{enumerate}
    \item Risk model;
    \item Time model;
    \item Block-diag model;
    \item Complete model.
   \end{enumerate}
  \end{multicols}
 \vspace{-0.6cm}
 \item[Two] CIF configurations:
  \begin{multicols}{2}
   \begin{description}
    \item[Low] max incidence \(\approx 0.15\);
    \item[High] max incidence \(\approx 0.60\).
   \end{description}
  \end{multicols}
\end{description}

\vspace{-0.3cm}
For each of those \({\color{UniBlue}{\bm{4}}} \times
{\color{UniBlue}{\bm{2}}} = {\color{UniBlue}{\bm{8}}}\) scenarios, we
vary the sample and cluster sizes:

\vspace{-0.2cm}
\begin{columns}
 \column{5cm}
  \begin{align*}
   &\textbf{\textit{\color{UniBlue}{5000 data points}}}\\
   \bullet~&\text{2500 clusters of}~\textbf{\color{UniBlue}{size 2}};\\
   \bullet~&\text{1000 clusters of}~\textbf{\color{UniBlue}{size 5}};\\
   \bullet~&\text{500 clusters of}~\textbf{\color{UniBlue}{size 10}}.
  \end{align*}
 \column{5cm}
  \begin{align*}
   &\textbf{\textit{\color{UniBlue}{30000 data points}}}\\
   \bullet~&\text{15000 clusters of}~\textbf{\color{UniBlue}{size 2}};\\
   \bullet~&\text{6000 clusters of}~\textbf{\color{UniBlue}{size 5}};\\
   \bullet~&\text{3000 clusters of}~\textbf{\color{UniBlue}{size 10}}.
  \end{align*}
 \column{5cm}
  \begin{align*}
   &\textbf{\textit{\color{UniBlue}{60000 data points}}}\\
   \bullet~&\text{30000 clusters of}~\textbf{\color{UniBlue}{size 2}};\\
   \bullet~&\text{12000 clusters of}~\textbf{\color{UniBlue}{size 5}};\\
   \bullet~&\text{6000 clusters of}~\textbf{\color{UniBlue}{size 10}}.
  \end{align*}
\end{columns}

\vspace{-0.1cm}
\begin{block}{}
Totalizing, \({\color{UniBlue}{\bm{8}}} \times {\color{UniBlue}{\bm{3}}}
\times {\color{UniBlue}{\bm{3}}} = {\color{UniBlue}{\bm{72}}}\)
scenarios.\newline
For each scenario, we simulate \(\color{UniBlue}{\bm{500}}\) samples,
totalizing \({\color{UniBlue}{\bm{72}}} \times
{\color{UniBlue}{\bm{500}}} = {\color{UniBlue}{\bm{36000}}}\) model
fittings.
\end{block}

### Simulation study results

First of all, the **time**.

+ The *non-complete* models (2D Laplace aprox.) are kind of fast,\newline
  taking always **less than 5 min**.

+ In the most expensive scenarios (30K 4D Laplaces),\newline
  **the complete model takes 30 min**.\newline
  In a **full R** implementation with 10K 4D Laplaces, it **took
  30hrs**. \textcolor{UniBlue}{\textbf{TMB is fast}}.
 
+ We also did a Bayesian analysis via Stan/NUTS-HMC [@RStan].

  - **1 week of parallelized processing** for a 2500 size 2 clusters
    scenario with tuned NUTS. This just reinforces the MCMC
    impracticability for some complex models.

**Parameters estimation**.

+ The *non-complete* models fail to learn the data.\newline
  They appear to be *not structured enough* to capture the data
  characteristics.

# Estimation of \(\sigma^{2}\)

# Examples of quasi-likelihood functions

# A higher order theory

### Take-home message

\vspace{-0.55cm}
\begin{minipage}{13cm}
 \begin{block}{}
  \textbf{The complete model works}. It's not magnificent, but it works.
  \vspace{0.2cm}
  \begin{enumerate}
   \item It works better in the high CIF scenarios;
   \vspace{0.15cm}
   \item As expected, as the sample size increases the results get
         better;
   \vspace{0.15cm}
   \item We do not see any considerable performance difference between
         cluster/family sizes;
   \vspace{0.15cm}
   \item Satisfactory full likelihood analysis under the maximum
         likelihood estimation framework (the estimates bias-variance
         could be smaller).
   \end{enumerate}
 \end{block}
\end{minipage}
\vspace{0.1cm}
What else can we do?

1. Instead of a conditional approach (latent effects model),\newline
   we can try a marginal approach e.g., an McGLM [@mcglm];

2. We can also try a copula [@copulas], on maybe two fronts:\newline 1)
   for a full specification; 2) to accommodate the within-cluster
   dependence.

\includegraphics[height=0.5cm]{logo/book.png}
For more read @laurence master thesis.

### Thanks for watching and have a great day

\vspace{0.5cm}
Special thanks to

\bigskip
\begin{columns}
 \column{1.5cm}
  \centering\includegraphics{logo/ppgmne-logo.png}
 \column{13.75cm}
  {\large \textbf{PPGMNE}}\newline
  Programa de Pós-Graduação em\newline
  Métodos Numéricos em Engenharia
\end{columns}

\bigskip
\begin{columns}
 \column{2cm}
  \includegraphics[height=2cm]{logo/capes.jpg}
 \column{3cm}
  \includegraphics[height=2cm]{logo/ufpr.png}
 \column{4.5cm}
  Joint work with
  \vspace{0.2cm}\newline
  Wagner H. Bonat\newline
  \url{http://leg.ufpr.br/~wagner}
 \column{4.75cm}
  \textcolor{white}{Joint work with}
  \vspace{0.2cm}\newline
  Paulo Justiniano Ribeiro Jr.\newline
  \url{http://leg.ufpr.br/~paulojus}
\end{columns}

\vspace{1.5cm}
\begin{columns}
 \column{10cm}
 \column{5cm}
  \includegraphics[height=0.3cm,angle=90]{../../laurence.jpg}
  \hspace{0.05cm}
  \href{https://henriquelaureano.github.io}{henriquelaureano.github.io}
\end{columns}
